{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import io  # Used to convert bytes to a file-like object\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#set up storage\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
        "container_name = \"publicdata\"\n",
        "\n",
        "#create client\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)"
      ],
      "metadata": {
        "id": "lTFFWHUjblxk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables to accumulate dimensions\n",
        "total_images = 0\n",
        "total_width = 0\n",
        "total_height = 0\n",
        "\n",
        "# Loop through all blobs and accumulate dimensions\n",
        "blobs = container_client.list_blobs()\n",
        "for blob in blobs:\n",
        "    if blob.name.endswith(\".jpg\"):\n",
        "        # Download the image\n",
        "        image_blob_client = container_client.get_blob_client(blob.name)\n",
        "        image_content = image_blob_client.download_blob().readall()\n",
        "\n",
        "        # Decode image with OpenCV\n",
        "        image = cv2.imdecode(np.frombuffer(image_content, np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Accumulate dimensions\n",
        "        height, width, _ = image.shape\n",
        "        total_images += 1\n",
        "        total_width += width\n",
        "        total_height += height\n",
        "\n",
        "# Calculate summary statistics\n",
        "average_width = total_width / total_images\n",
        "average_height = total_height / total_images\n",
        "\n",
        "print(f\"Total images: {total_images}\")\n",
        "print(f\"Average width: {average_width}\")\n",
        "print(f\"Average height: {average_height}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcw4gyRd0NT4",
        "outputId": "758fb7b7-02c6-4625-d5bd-9bd521649aef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 51\n",
            "Average width: 1574.9019607843138\n",
            "Average height: 885.8823529411765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for preprocessing\n",
        "desired_width = 64  # Desired width for resizing\n",
        "desired_height = 64  # Desired height for resizing\n",
        "median_kernel_size = 5  # Kernel size for median blur\n",
        "canny_threshold1 = 0.4  # Lower threshold for Canny edge detection\n",
        "canny_threshold2 = 0.8  # Upper threshold for Canny edge detection\n",
        "\n",
        "# Augmentation parameters\n",
        "flip_horizontal = True\n",
        "flip_vertical = True\n",
        "rotate_90 = True\n",
        "\n",
        "# Function to apply preprocessing steps\n",
        "def preprocess_image(image):\n",
        "    # Convert image to grayscale\n",
        "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(grayscale_image, (desired_width, desired_height))\n",
        "\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    normalized_image = np.uint8(resized_image / 255.0)\n",
        "\n",
        "    # Apply histogram equalization\n",
        "    equalized_image = cv2.equalizeHist(normalized_image).astype(np.uint8)\n",
        "\n",
        "    # Apply noise reduction filters (median blur)\n",
        "    blurred_image = cv2.medianBlur(equalized_image, median_kernel_size).astype(np.uint8)\n",
        "\n",
        "    # Apply edge detection using Canny\n",
        "    edges = cv2.Canny(blurred_image, canny_threshold1, canny_threshold2)\n",
        "\n",
        "    return edges\n",
        "\n",
        "# Loop through all blobs and process images directly\n",
        "blobs = container_client.list_blobs()\n",
        "for blob in blobs:\n",
        "    if blob.name.endswith(\".jpg\"):\n",
        "        # Download the original image\n",
        "        image_blob_client = container_client.get_blob_client(blob.name)\n",
        "        image_content = image_blob_client.download_blob().readall()\n",
        "\n",
        "        # Preprocess the original image\n",
        "        nparr = np.frombuffer(image_content, np.uint8)\n",
        "        original_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)  # Convert bytes to numpy array\n",
        "\n",
        "        # Apply augmentations\n",
        "        augmentations = []\n",
        "\n",
        "        if flip_horizontal:\n",
        "            augmentations.append(cv2.flip(original_image, 1))\n",
        "\n",
        "        if flip_vertical:\n",
        "            augmentations.append(cv2.flip(original_image, 0))\n",
        "\n",
        "        if rotate_90:\n",
        "            augmentations.append(cv2.rotate(original_image, cv2.ROTATE_90_CLOCKWISE))\n",
        "\n",
        "        # Save augmented images and preprocess\n",
        "        for i, augmented_image in enumerate(augmentations):\n",
        "            # Preprocess the augmented image\n",
        "            preprocessed_image = preprocess_image(augmented_image)\n",
        "\n",
        "            # Save preprocessed augmented image to a temporary file\n",
        "            temp_file_path = f\"preprocessed_augmented_image_{i}.jpg\"\n",
        "            cv2.imwrite(temp_file_path, (preprocessed_image * 255).astype(np.uint8))  # Save preprocessed image after preprocessing steps\n",
        "\n",
        "            # Upload the preprocessed augmented image back to Azure Blob Storage\n",
        "            with open(temp_file_path, \"rb\") as data:\n",
        "                container_client.upload_blob(name=\"preprocessed/\" + temp_file_path, data=data, overwrite = True)\n",
        "\n",
        "            # Clean up temporary file\n",
        "            os.remove(temp_file_path)\n",
        "\n",
        "        # Preprocess the original image\n",
        "        preprocessed_original_image = preprocess_image(original_image)\n",
        "\n",
        "        # Save preprocessed original image to a temporary file\n",
        "        original_temp_file_path = \"preprocessed_original_temp_image.jpg\"\n",
        "        cv2.imwrite(original_temp_file_path, preprocessed_original_image) # Save preprocessed image after preprocessing steps\n",
        "\n",
        "        # Upload the preprocessed original image back to Azure Blob Storage\n",
        "        with open(original_temp_file_path, \"rb\") as data:\n",
        "            container_client.upload_blob(name=\"preprocessed/\" + original_temp_file_path, data=data, overwrite = True)\n",
        "\n",
        "        # Clean up original temporary file\n",
        "        os.remove(original_temp_file_path)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "FQ_dElQXbpZr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cc-klE4EnLvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2cbgngjnLP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CN3DGmcNnKE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3T8-SRxnMYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2J06gtOnbMF-"
      }
    }
  ]
}