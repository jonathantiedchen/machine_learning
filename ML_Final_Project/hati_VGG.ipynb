{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"datacomplete\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filepaths\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/2_Semester/ML/Assignments/machine_learning/ML_Final_Project/labeled_train.csv\")\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df.sample(n=3000, random_state=42)\n",
    "\n",
    "filenames = df[\"filename\"]\n",
    "# convert each string in the DataFrame to a list\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "\n",
    "# convert each list in the DataFrame to a numpy array\n",
    "df['labels'] = df['labels'].apply(np.array)\n",
    "\n",
    "# store all the arrays in a list\n",
    "labels = df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  700\n",
      "Test Set:  150\n",
      "Validation Set 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['filename'], df['labels'], test_size=0.2)\n",
    "\n",
    "# First split: Splitting into 80% for the temporary training set and 20% for the test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(df['filename'], df['labels'], test_size=0.15, random_state=42)\n",
    "\n",
    "# Second split: Splitting the temporary training set into 87.5% for training and 12.5% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "\n",
    "#convert train and test labels to arrays\n",
    "y_train = y_train.apply(np.array).tolist()\n",
    "y_test = y_test.apply(np.array).tolist()\n",
    "y_val = y_val.apply(np.array).tolist()\n",
    "\n",
    "#remove labels\n",
    "y_train = [arr[[1,5,6]] for arr in y_train]\n",
    "y_test = [arr[[1,5,6]] for arr in y_test]\n",
    "y_val = [arr[[1,5,6]] for arr in y_val]\n",
    "\n",
    "print(\"Training Set: \", len(X_train))\n",
    "print(\"Test Set: \", len(X_test))\n",
    "print(\"Validation Set\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224\n",
    "channels=3\n",
    "\n",
    "batch_size = 224 # Big enough to measure an F1-score\n",
    "autotune = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "shuffle_buffer_size = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create data (input for models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from Azure Blob Storage.\"\"\"\n",
    "    blob_client = container_client.get_blob_client(path)\n",
    "    blob_data = blob_client.download_blob().readall()  # Directly read all bytes\n",
    "    return io.BytesIO(blob_data)\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"Loads an image, decodes it to grayscale, resizes, and normalizes it.\"\"\"\n",
    "    # Load image\n",
    "    image_file = load_image(path.numpy().decode('utf-8'))\n",
    "    # Decode the image to grayscale\n",
    "    image_tensor = tf.io.decode_image(image_file.getvalue(), channels=channels)\n",
    "    # Resize the image\n",
    "    image_resized = tf.image.resize(image_tensor, [image_size, image_size])\n",
    "    # Normalize the image data\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "def process_tensor(path, label):\n",
    "    \"\"\"Function to load an image from blob storage, decode, resize, and normalize it.\"\"\"\n",
    "    image_normalized = tf.py_function(load_and_preprocess_image, [path], tf.float32)\n",
    "    # Ensure the shape is set correctly for grayscale\n",
    "    image_normalized.set_shape([image_size, image_size, channels])\n",
    "    return image_normalized, label\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Creates a TensorFlow dataset from filenames and labels.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(process_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "        \n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train)\n",
    "test_ds = create_dataset(X_test, y_test, False)\n",
    "val_ds = create_dataset(X_val, y_val, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):  # Here, take(1) takes the first batch\n",
    "    print(\"Images:\", images.numpy())  # Convert tensor to numpy array and print\n",
    "    print(\"Labels:\", labels.numpy())  # Convert tensor to numpy array and print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features array: (256, 224, 224, 3)\n",
      "Shape of labels array: (256, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 10:50:39.675819: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "#check dataset shape\n",
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot one image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_image_from_dataset(dataset, index):\n",
    "    # Take one batch from the dataset\n",
    "    for images, labels in dataset.take(index):\n",
    "        # Assuming the image tensor is in the shape [batch_size, height, width, channels]\n",
    "        # and you need the first image in the batch\n",
    "        first_image = images[0]  # This is a tensor\n",
    "\n",
    "        # Check if the image needs to be squeezed (in case it's a grayscale image with a single channel)\n",
    "        if first_image.shape[-1] == 1:\n",
    "            first_image = tf.squeeze(first_image, axis=-1)\n",
    "        \n",
    "        # Convert tensor to numpy for plotting\n",
    "        first_image_np = first_image.numpy()\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(first_image_np, cmap='gray')\n",
    "        plt.title(f'Label: {labels[0].numpy()}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage with your train_ds dataset\n",
    "plot_first_image_from_dataset(train_ds,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Trained VGG\n",
    "Source: https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "_input = Input((224,224,1)) \n",
    "\n",
    "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
    "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "pool4  = MaxPooling2D((2, 2))(conv10)\n",
    "\n",
    "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
    "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
    "pool5  = MaxPooling2D((2, 2))(conv13)\n",
    "\n",
    "flat   = Flatten()(pool5)\n",
    "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
    "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
    "output = Dense(8, activation=\"sigmoid\")(dense2) #adapted number of outputs and outputfunction\n",
    "\n",
    "vgg16_model  = Model(inputs=_input, outputs=output)\n",
    "\n",
    "LR = 1e-5 #why?\n",
    "EPOCHS = 10 #why?\n",
    "\n",
    "\n",
    "#compile the model\n",
    "vgg16_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LR),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##provide a model summary\n",
    "vgg16_model.summary()\n",
    "\n",
    "#fit the model\n",
    "vgg16_model.fit(\n",
    "    train_ds,\n",
    "    validation_split = 0.2,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get prediction\n",
    "predictions = vgg16_model.predict(train_ds)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, \n",
    "           to_file='vgg.png',\n",
    "           show_shapes=True,\n",
    "           show_dtype=True,\n",
    "           show_layer_names=True,\n",
    "           show_layer_activations=True,\n",
    "           show_trainable=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2: https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "\n",
    "model_mnv2 = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(7, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model_mnv2.summary()\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    predictions = model_mnv2.predict(images)  # Only pass image data\n",
    "    #print(predictions[:1])\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception.v3: https://towardsdatascience.com/understanding-the-amazon-rainforest-with-multi-label-classification-vgg-19-inceptionv3-5084544fb655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14s/step - accuracy: 0.2822 - loss: 17.9969 - val_accuracy: 0.1333 - val_loss: 31.6597\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13s/step - accuracy: 0.2422 - loss: 29.7807 - val_accuracy: 0.1400 - val_loss: 28.3067\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14s/step - accuracy: 0.2949 - loss: 25.2096 - val_accuracy: 0.1200 - val_loss: 24.1282\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13s/step - accuracy: 0.0790 - loss: 24.3685 - val_accuracy: 0.0867 - val_loss: 24.4417\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13s/step - accuracy: 0.2980 - loss: 23.5756 - val_accuracy: 0.5000 - val_loss: 17.1135\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3018 - loss: 19.6772 - val_accuracy: 0.0933 - val_loss: 26.7201\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14s/step - accuracy: 0.1291 - loss: 27.7690 - val_accuracy: 0.5533 - val_loss: 27.0175\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13s/step - accuracy: 0.4087 - loss: 31.2693 - val_accuracy: 0.0467 - val_loss: 31.8115\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.1938 - loss: 35.2088 - val_accuracy: 0.2667 - val_loss: 32.1335\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13s/step - accuracy: 0.3132 - loss: 38.5397 - val_accuracy: 0.0933 - val_loss: 38.4636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2964daf20>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "def create_inception_v3_model():\n",
    "    inceptionv3 = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in inceptionv3.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Adding custom layers\n",
    "    x = inceptionv3.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Ensure this reduces all spatial dimensions\n",
    "    x = Dense(4096, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(3, activation=\"sigmoid\")(x)  # Adjust the number of output units to match the number of classes\n",
    "\n",
    "    # Creating the final model\n",
    "    model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "inceptionv3_model = create_inception_v3_model()\n",
    "\n",
    "# Set up the model checkpoint\n",
    "#model_checkpoint = ModelCheckpoint('inceptionv3_model.h5', monitor=\"val_accuracy\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Assuming train_ds, X_test, y_test are properly defined\n",
    "inceptionv3_model.fit(train_ds,\n",
    "                      validation_data = val_ds, \n",
    "                      epochs=10, \n",
    "                      #callbacks=[model_checkpoint])\n",
    ")           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 1 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 1 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 1 1 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 1 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 1 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 1 1 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 1 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 1 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 1 1 0 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 1 0 0 1 0 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [1. 1. 1. 1. 1. 1. 1.] Actual Label: [1 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "for images, labels in test_ds:\n",
    "    predictions = inceptionv3_model.predict(images)  # Only pass image data\n",
    "    #print(predictions[:1])\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16: https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vgg16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 90s/step - accuracy: 0.4557 - loss: 0.9414 - val_accuracy: 0.6000 - val_loss: 0.5944\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 87s/step - accuracy: 0.5542 - loss: 0.5646 - val_accuracy: 0.6000 - val_loss: 0.5363\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 89s/step - accuracy: 0.5527 - loss: 0.4981 - val_accuracy: 0.6000 - val_loss: 0.5106\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 86s/step - accuracy: 0.5605 - loss: 0.4687 - val_accuracy: 0.6000 - val_loss: 0.5219\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 90s/step - accuracy: 0.5645 - loss: 0.4562 - val_accuracy: 0.5933 - val_loss: 0.5207\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 89s/step - accuracy: 0.5477 - loss: 0.4356 - val_accuracy: 0.6000 - val_loss: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x12aea8670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(3, activation='sigmoid')\n",
    "\n",
    "\n",
    "model_vgg = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model_vgg.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "model_vgg.fit(train_ds, validation_data = val_ds, epochs=10, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6s/step\n",
      "Prediction: [0.03325642 0.819588   0.44481274] Actual Label: [0 1 0]\n",
      "Prediction: [0.03298372 0.7756917  0.28415653] Actual Label: [0 1 0]\n",
      "Prediction: [0.01971993 0.82212216 0.27173173] Actual Label: [0 1 0]\n",
      "Prediction: [0.02881509 0.7853935  0.32783452] Actual Label: [0 1 1]\n",
      "Prediction: [0.02643297 0.80478036 0.36957818] Actual Label: [1 0 1]\n",
      "Prediction: [0.03034144 0.8443955  0.43575382] Actual Label: [0 0 0]\n",
      "Prediction: [0.03646141 0.8653222  0.5767437 ] Actual Label: [1 1 1]\n",
      "Prediction: [0.04153549 0.79053783 0.37910905] Actual Label: [0 1 0]\n",
      "Prediction: [0.02478776 0.8481702  0.40732867] Actual Label: [0 1 0]\n",
      "Prediction: [0.03914318 0.8362499  0.39225364] Actual Label: [0 1 0]\n",
      "Prediction: [0.02710096 0.8233099  0.36825547] Actual Label: [0 1 0]\n",
      "Prediction: [0.03341808 0.82309467 0.36281875] Actual Label: [0 1 0]\n",
      "Prediction: [0.02505509 0.7783076  0.33538875] Actual Label: [0 0 0]\n",
      "Prediction: [0.03583912 0.82933664 0.40166944] Actual Label: [0 1 0]\n",
      "Prediction: [0.03231628 0.8413049  0.43828052] Actual Label: [0 0 0]\n",
      "Prediction: [0.03885972 0.8308969  0.5127834 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03693146 0.80349815 0.48621255] Actual Label: [0 0 1]\n",
      "Prediction: [0.03079648 0.77786106 0.3256737 ] Actual Label: [0 1 1]\n",
      "Prediction: [0.03048023 0.78561217 0.38848472] Actual Label: [0 0 0]\n",
      "Prediction: [0.02448511 0.857666   0.40742728] Actual Label: [1 1 0]\n",
      "Prediction: [0.02943604 0.8108052  0.3557691 ] Actual Label: [1 1 1]\n",
      "Prediction: [0.02868457 0.7828922  0.3151754 ] Actual Label: [0 1 1]\n",
      "Prediction: [0.02385619 0.76192105 0.21385479] Actual Label: [0 1 0]\n",
      "Prediction: [0.02902013 0.74138355 0.22741343] Actual Label: [0 0 0]\n",
      "Prediction: [0.0370529 0.8262269 0.4016969] Actual Label: [0 1 0]\n",
      "Prediction: [0.02823353 0.7974044  0.3578158 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.0326985 0.8594651 0.4825375] Actual Label: [0 1 0]\n",
      "Prediction: [0.02004456 0.86161953 0.3818212 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.04722856 0.8144539  0.44103765] Actual Label: [0 1 0]\n",
      "Prediction: [0.03488241 0.8355074  0.4679316 ] Actual Label: [1 1 1]\n",
      "Prediction: [0.0352492 0.8112872 0.3092595] Actual Label: [0 1 0]\n",
      "Prediction: [0.02350894 0.8341834  0.26995066] Actual Label: [0 1 1]\n",
      "Prediction: [0.02823403 0.81107914 0.32420403] Actual Label: [1 0 0]\n",
      "Prediction: [0.04148647 0.8265451  0.47167826] Actual Label: [0 0 1]\n",
      "Prediction: [0.0390523 0.8137562 0.4038358] Actual Label: [0 0 0]\n",
      "Prediction: [0.03229342 0.8026309  0.42009363] Actual Label: [0 0 0]\n",
      "Prediction: [0.02837715 0.7923902  0.3258667 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.02347136 0.7868449  0.30977383] Actual Label: [0 1 0]\n",
      "Prediction: [0.04309799 0.8344885  0.49207675] Actual Label: [0 1 0]\n",
      "Prediction: [0.04070556 0.76968706 0.38875636] Actual Label: [0 1 0]\n",
      "Prediction: [0.03058923 0.7816945  0.2730965 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03599875 0.77291846 0.31979486] Actual Label: [0 0 0]\n",
      "Prediction: [0.02324976 0.7846085  0.37228313] Actual Label: [0 0 0]\n",
      "Prediction: [0.02801716 0.82957447 0.44843638] Actual Label: [0 0 0]\n",
      "Prediction: [0.03259801 0.770387   0.27993053] Actual Label: [0 1 0]\n",
      "Prediction: [0.0202074  0.83020204 0.29680002] Actual Label: [0 0 0]\n",
      "Prediction: [0.04832619 0.8499404  0.50626093] Actual Label: [0 1 0]\n",
      "Prediction: [0.02057735 0.7765163  0.33627596] Actual Label: [0 1 0]\n",
      "Prediction: [0.02734067 0.74401414 0.22707078] Actual Label: [0 1 0]\n",
      "Prediction: [0.03472016 0.7642272  0.31393644] Actual Label: [0 0 0]\n",
      "Prediction: [0.04342533 0.7669661  0.33133298] Actual Label: [0 1 0]\n",
      "Prediction: [0.03902861 0.8336271  0.51475585] Actual Label: [0 0 0]\n",
      "Prediction: [0.04901525 0.81280994 0.41168004] Actual Label: [1 1 0]\n",
      "Prediction: [0.03687136 0.7492204  0.36300385] Actual Label: [0 1 0]\n",
      "Prediction: [0.02758558 0.7661942  0.25245208] Actual Label: [0 0 0]\n",
      "Prediction: [0.02503545 0.8141178  0.37400296] Actual Label: [0 0 0]\n",
      "Prediction: [0.02911652 0.8859811  0.5653666 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03100338 0.77925104 0.30276996] Actual Label: [1 1 0]\n",
      "Prediction: [0.03112604 0.7964653  0.38111794] Actual Label: [0 1 0]\n",
      "Prediction: [0.02835977 0.7585821  0.36248124] Actual Label: [0 0 0]\n",
      "Prediction: [0.03770691 0.8610475  0.47650835] Actual Label: [0 1 0]\n",
      "Prediction: [0.02959806 0.80463684 0.39399412] Actual Label: [1 0 1]\n",
      "Prediction: [0.04453172 0.8130525  0.45764995] Actual Label: [0 1 0]\n",
      "Prediction: [0.03201649 0.8702209  0.68098736] Actual Label: [0 1 1]\n",
      "Prediction: [0.03685338 0.79433066 0.30668125] Actual Label: [0 1 1]\n",
      "Prediction: [0.04163613 0.70266277 0.22599256] Actual Label: [0 0 0]\n",
      "Prediction: [0.04846455 0.81541187 0.48522004] Actual Label: [0 1 0]\n",
      "Prediction: [0.02908377 0.84237313 0.50476366] Actual Label: [0 1 1]\n",
      "Prediction: [0.02716474 0.84690887 0.5011472 ] Actual Label: [1 0 1]\n",
      "Prediction: [0.03963224 0.8725803  0.40836188] Actual Label: [0 1 0]\n",
      "Prediction: [0.03931349 0.81948876 0.42084643] Actual Label: [0 1 0]\n",
      "Prediction: [0.0249137 0.7991457 0.4058498] Actual Label: [0 1 0]\n",
      "Prediction: [0.03220068 0.7576781  0.30435917] Actual Label: [0 0 0]\n",
      "Prediction: [0.03532523 0.8123349  0.3726749 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.01888312 0.78616416 0.37029946] Actual Label: [0 0 0]\n",
      "Prediction: [0.03040127 0.77193063 0.3425271 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.03266592 0.8607898  0.4935684 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03724628 0.82552207 0.40936956] Actual Label: [0 1 0]\n",
      "Prediction: [0.04364388 0.81262356 0.38552475] Actual Label: [0 1 0]\n",
      "Prediction: [0.02828652 0.8475578  0.504234  ] Actual Label: [0 0 0]\n",
      "Prediction: [0.02840044 0.83189076 0.4793047 ] Actual Label: [0 0 1]\n",
      "Prediction: [0.04126761 0.8025799  0.38043422] Actual Label: [0 1 1]\n",
      "Prediction: [0.03676524 0.79188746 0.42785475] Actual Label: [0 1 0]\n",
      "Prediction: [0.0390865 0.8533949 0.5495835] Actual Label: [0 1 0]\n",
      "Prediction: [0.03333316 0.74850607 0.27685657] Actual Label: [0 0 0]\n",
      "Prediction: [0.03584511 0.8403823  0.430577  ] Actual Label: [0 1 1]\n",
      "Prediction: [0.04187313 0.83311146 0.4306377 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.02539589 0.8117045  0.32209376] Actual Label: [0 0 0]\n",
      "Prediction: [0.02608905 0.78077096 0.30751374] Actual Label: [0 0 0]\n",
      "Prediction: [0.01819657 0.78100127 0.24342072] Actual Label: [1 1 0]\n",
      "Prediction: [0.03312458 0.8197724  0.5249181 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03774054 0.82170725 0.4682604 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03364679 0.8557257  0.4003803 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.02044999 0.83290666 0.31292108] Actual Label: [0 1 0]\n",
      "Prediction: [0.02804788 0.80620694 0.33647874] Actual Label: [1 1 1]\n",
      "Prediction: [0.02181725 0.84290534 0.46826264] Actual Label: [0 1 0]\n",
      "Prediction: [0.02979975 0.79393584 0.37559167] Actual Label: [1 1 1]\n",
      "Prediction: [0.02904591 0.7820097  0.26512924] Actual Label: [0 1 1]\n",
      "Prediction: [0.03794911 0.83392256 0.46832618] Actual Label: [1 0 0]\n",
      "Prediction: [0.04259638 0.85793185 0.4694537 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03375264 0.7228603  0.282116  ] Actual Label: [0 0 0]\n",
      "Prediction: [0.02454084 0.73169464 0.22366185] Actual Label: [0 0 0]\n",
      "Prediction: [0.0249381  0.7870113  0.28829515] Actual Label: [0 1 1]\n",
      "Prediction: [0.02999683 0.83389884 0.40912762] Actual Label: [0 1 1]\n",
      "Prediction: [0.03500903 0.84495074 0.4218354 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.02503628 0.8552666  0.42136097] Actual Label: [1 1 1]\n",
      "Prediction: [0.03075812 0.8206828  0.3943965 ] Actual Label: [0 1 1]\n",
      "Prediction: [0.03077062 0.77831346 0.23702763] Actual Label: [0 0 0]\n",
      "Prediction: [0.0272339  0.79942334 0.36141178] Actual Label: [0 1 0]\n",
      "Prediction: [0.02606401 0.8270498  0.36772156] Actual Label: [0 0 0]\n",
      "Prediction: [0.02279182 0.78622866 0.27375793] Actual Label: [0 0 0]\n",
      "Prediction: [0.03426142 0.79635894 0.4140398 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03019697 0.83165795 0.41800547] Actual Label: [0 0 0]\n",
      "Prediction: [0.02547922 0.78096837 0.27996293] Actual Label: [0 1 0]\n",
      "Prediction: [0.04494574 0.8285497  0.43638986] Actual Label: [1 1 0]\n",
      "Prediction: [0.03634518 0.81237644 0.43507698] Actual Label: [0 1 0]\n",
      "Prediction: [0.04256056 0.72695494 0.29555383] Actual Label: [0 0 0]\n",
      "Prediction: [0.04117483 0.8397208  0.38589746] Actual Label: [0 1 0]\n",
      "Prediction: [0.0356296 0.8695118 0.5354721] Actual Label: [1 1 1]\n",
      "Prediction: [0.02949234 0.829905   0.40067282] Actual Label: [0 1 0]\n",
      "Prediction: [0.03817409 0.7797611  0.371964  ] Actual Label: [1 1 0]\n",
      "Prediction: [0.02924257 0.8287813  0.3461269 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03490216 0.811469   0.39582896] Actual Label: [0 1 0]\n",
      "Prediction: [0.03901959 0.8274447  0.33355677] Actual Label: [0 1 0]\n",
      "Prediction: [0.03299602 0.7821533  0.2792649 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.02900129 0.7741778  0.2911722 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.04271122 0.7923967  0.3347431 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.02674108 0.85054916 0.4177826 ] Actual Label: [1 1 1]\n",
      "Prediction: [0.03382442 0.8518211  0.5210354 ] Actual Label: [0 1 1]\n",
      "Prediction: [0.02507644 0.82701415 0.36031404] Actual Label: [0 1 0]\n",
      "Prediction: [0.04549025 0.82097244 0.42840824] Actual Label: [0 1 1]\n",
      "Prediction: [0.03276749 0.875807   0.4954275 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.02884526 0.85086787 0.52132565] Actual Label: [0 1 0]\n",
      "Prediction: [0.03934968 0.80362624 0.3894706 ] Actual Label: [1 0 1]\n",
      "Prediction: [0.02978124 0.8004357  0.39364973] Actual Label: [0 0 0]\n",
      "Prediction: [0.02556626 0.78103125 0.29721075] Actual Label: [0 0 0]\n",
      "Prediction: [0.0278622  0.7678701  0.28646162] Actual Label: [1 0 0]\n",
      "Prediction: [0.03625505 0.72431314 0.26522598] Actual Label: [0 0 0]\n",
      "Prediction: [0.0353933 0.8180782 0.3861463] Actual Label: [1 0 0]\n",
      "Prediction: [0.02852743 0.79754055 0.32547292] Actual Label: [0 0 1]\n",
      "Prediction: [0.03669912 0.8112143  0.44203368] Actual Label: [0 1 0]\n",
      "Prediction: [0.04380949 0.8265058  0.4351049 ] Actual Label: [1 1 1]\n",
      "Prediction: [0.0350373  0.84622794 0.44741362] Actual Label: [0 1 0]\n",
      "Prediction: [0.03581342 0.77935255 0.3102394 ] Actual Label: [0 0 0]\n",
      "Prediction: [0.05015516 0.8515556  0.4496267 ] Actual Label: [0 1 0]\n",
      "Prediction: [0.03203509 0.8388798  0.46583274] Actual Label: [0 1 1]\n",
      "Prediction: [0.03597947 0.7997003  0.3497658 ] Actual Label: [1 0 1]\n",
      "Prediction: [0.02886835 0.8117881  0.35116065] Actual Label: [0 1 0]\n",
      "Prediction: [0.03018691 0.7923548  0.33286384] Actual Label: [0 1 1]\n",
      "Prediction: [0.03921685 0.8469293  0.45382744] Actual Label: [0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_ds:\n",
    "    predictions = model_vgg.predict(images)  # Only pass image data\n",
    "    #print(predictions[:1])\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50: https://datagen.tech/guides/computer-vision/resnet-50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19s/step - accuracy: 0.1033 - loss: 4.1370 - val_accuracy: 0.0867 - val_loss: 4.4002\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 19s/step - accuracy: 0.1352 - loss: 4.1698 - val_accuracy: 0.0867 - val_loss: 4.3835\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 22s/step - accuracy: 0.1479 - loss: 4.0888 - val_accuracy: 0.0867 - val_loss: 4.3678\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21s/step - accuracy: 0.1323 - loss: 4.0540 - val_accuracy: 0.0867 - val_loss: 4.3515\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 20s/step - accuracy: 0.1338 - loss: 4.1141 - val_accuracy: 0.0867 - val_loss: 4.3346\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 21s/step - accuracy: 0.1333 - loss: 4.0541 - val_accuracy: 0.0867 - val_loss: 4.3170\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 21s/step - accuracy: 0.1299 - loss: 4.1131 - val_accuracy: 0.0867 - val_loss: 4.2990\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 22s/step - accuracy: 0.1362 - loss: 4.0270 - val_accuracy: 0.0867 - val_loss: 4.2801\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 22s/step - accuracy: 0.1362 - loss: 4.1035 - val_accuracy: 0.0867 - val_loss: 4.2620\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20s/step - accuracy: 0.1318 - loss: 4.0819 - val_accuracy: 0.0867 - val_loss: 4.2446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30b99c160>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plotter_lib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL as image_lib\n",
    "\n",
    "import tensorflow as tflow\n",
    "\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "resnet_model = Sequential()\n",
    "\n",
    "rn50_base = tflow.keras.applications.ResNet50(\n",
    "    weights = \"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "for each_layer in rn50_base.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "resnet_model.add(rn50_base)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "resnet_model.add(Dense(7, activation='sigmoid'))\n",
    "\n",
    "resnet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "resnet_model.fit(train_ds, validation_data = val_ds, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step\n",
      "Prediction: [0.808961   0.3408545  0.12461656 0.16093753 0.05578974 0.320024\n",
      " 0.44170302] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.745914   0.3542185  0.1230882  0.18771501 0.05531713 0.31288648\n",
      " 0.424262  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.74697053 0.34362268 0.10176412 0.16764787 0.04852271 0.28684488\n",
      " 0.39359173] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.8429002  0.32981536 0.1052464  0.13855554 0.04150832 0.31023103\n",
      " 0.44934812] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8301681  0.3485725  0.1101438  0.14774078 0.04754231 0.32860145\n",
      " 0.44287384] Actual Label: [1 1 0 1 0 1 1]\n",
      "Prediction: [0.77808714 0.3326846  0.09886213 0.15719482 0.03974034 0.28754458\n",
      " 0.42077675] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7709208  0.33817938 0.09353303 0.15388034 0.03791275 0.29584286\n",
      " 0.40164486] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.76769364 0.32618228 0.08814462 0.1537395  0.0339381  0.2706281\n",
      " 0.4042217 ] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [0.76134753 0.34466508 0.09992874 0.15828186 0.04372464 0.3073616\n",
      " 0.3948033 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7867298  0.33598787 0.07172057 0.13143864 0.02972793 0.28088918\n",
      " 0.37583718] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.70991004 0.34237418 0.16612269 0.21958943 0.0800833  0.31050014\n",
      " 0.43659958] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7567718  0.37116188 0.13452612 0.1853667  0.06999184 0.34619296\n",
      " 0.4196186 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7845718  0.334254   0.10501549 0.15700193 0.04368808 0.29819718\n",
      " 0.41882238] Actual Label: [1 0 1 0 0 0 1]\n",
      "Prediction: [0.7508804  0.3515407  0.149137   0.2027812  0.06587361 0.32417893\n",
      " 0.45090258] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7989525  0.33387464 0.09136205 0.1425629  0.03872359 0.29240736\n",
      " 0.405594  ] Actual Label: [0 1 0 0 1 1 1]\n",
      "Prediction: [0.7660693  0.3381078  0.0916968  0.16056342 0.03770867 0.2781643\n",
      " 0.40844637] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.72944367 0.3690872  0.11014517 0.18500672 0.06054984 0.30347934\n",
      " 0.39348882] Actual Label: [1 1 0 1 0 1 0]\n",
      "Prediction: [0.75448895 0.37318328 0.12465052 0.19354306 0.06627827 0.31507915\n",
      " 0.4271151 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.77809685 0.3892187  0.08986805 0.14592756 0.05187429 0.35193554\n",
      " 0.3657211 ] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7906751  0.3118709  0.09716722 0.15062393 0.03528219 0.26924166\n",
      " 0.42485458] Actual Label: [0 0 0 1 1 0 0]\n",
      "Prediction: [0.7786637  0.37906    0.08691963 0.14427193 0.04613047 0.34010512\n",
      " 0.36991006] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7345153  0.34450004 0.13662963 0.19778223 0.05961131 0.30866402\n",
      " 0.43247995] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.6967129  0.37403402 0.11188649 0.20225702 0.06636565 0.28728876\n",
      " 0.38845798] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8201562  0.35751545 0.10299555 0.1445342  0.04894809 0.33176604\n",
      " 0.41913715] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7181222  0.36572677 0.08393533 0.15290704 0.04775679 0.3058581\n",
      " 0.33961338] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.82207257 0.3079213  0.11566345 0.15126146 0.03796022 0.29284757\n",
      " 0.46352765] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.80361444 0.3193967  0.11929966 0.16251147 0.04214735 0.29693574\n",
      " 0.4572831 ] Actual Label: [0 0 0 1 0 0 0]\n",
      "Prediction: [0.72041136 0.3807111  0.11596632 0.19321188 0.06835941 0.31426564\n",
      " 0.39213413] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.8069464  0.36196026 0.10054553 0.14394112 0.05345166 0.33006245\n",
      " 0.39725396] Actual Label: [1 1 0 0 1 1 1]\n",
      "Prediction: [0.78308666 0.36248052 0.08736941 0.14935327 0.04084731 0.31252775\n",
      " 0.3929459 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7648847  0.35788822 0.09328065 0.16403027 0.04868272 0.28337857\n",
      " 0.39608702] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.74930185 0.357151   0.09579898 0.16843481 0.04799353 0.2889853\n",
      " 0.3922824 ] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.75223035 0.32648626 0.11847539 0.1806264  0.0461567  0.28350413\n",
      " 0.43230504] Actual Label: [0 1 0 1 0 1 1]\n",
      "Prediction: [0.8247861  0.36986154 0.08485585 0.13417533 0.04106203 0.33184552\n",
      " 0.40292114] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.75355774 0.3397097  0.12408716 0.17484675 0.05665599 0.31037745\n",
      " 0.4120505 ] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7628914  0.31264162 0.14673458 0.18838695 0.05099959 0.29962754\n",
      " 0.46136433] Actual Label: [0 0 0 1 0 1 1]\n",
      "Prediction: [0.70417625 0.3475155  0.10642314 0.1817918  0.05319353 0.28588855\n",
      " 0.3787295 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8000949  0.3149742  0.13106783 0.16893086 0.04750615 0.29573005\n",
      " 0.4632491 ] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.73015445 0.37417045 0.10199573 0.17967446 0.05438243 0.3085763\n",
      " 0.38755217] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.81291914 0.3527493  0.12234982 0.16416392 0.04993314 0.3377462\n",
      " 0.45499694] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.7775339  0.32597718 0.09994759 0.14813179 0.04121937 0.29719943\n",
      " 0.39779392] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7742857  0.35344613 0.17036164 0.21144165 0.07186677 0.33926538\n",
      " 0.48590335] Actual Label: [1 0 0 0 1 0 1]\n",
      "Prediction: [0.80737674 0.37090194 0.11080588 0.15611155 0.05564931 0.34474602\n",
      " 0.42059186] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.75499177 0.3596712  0.09353269 0.15798773 0.04759327 0.30601126\n",
      " 0.37851432] Actual Label: [0 1 0 0 0 0 0]\n",
      "Prediction: [0.77229846 0.32358778 0.1293849  0.18225345 0.04921081 0.28894383\n",
      " 0.4539428 ] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.80246073 0.36314955 0.07616021 0.12737644 0.03705315 0.3219567\n",
      " 0.3825488 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.72821933 0.38395706 0.09121289 0.1524013  0.06084286 0.33356965\n",
      " 0.3370309 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7694612  0.3567228  0.10257619 0.16076712 0.04850364 0.31661424\n",
      " 0.3993751 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78060895 0.35949636 0.10660212 0.16096684 0.05201038 0.32118085\n",
      " 0.40712482] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7846029  0.34687057 0.09009457 0.1619504  0.0429094  0.26431683\n",
      " 0.41799197] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7754013  0.33911484 0.11390831 0.17586909 0.04483564 0.295053\n",
      " 0.44278562] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.8222123  0.3474558  0.11177289 0.1512244  0.04751371 0.32769254\n",
      " 0.4413684 ] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.72456557 0.34640944 0.08933891 0.16748758 0.04498303 0.2682298\n",
      " 0.3732973 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7981438  0.35114965 0.11772283 0.17604591 0.05204708 0.30007154\n",
      " 0.45571938] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7514624  0.3503501  0.1075512  0.17452759 0.05096744 0.29480174\n",
      " 0.40714955] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7934714  0.32711214 0.11292097 0.17349516 0.04427854 0.27073574\n",
      " 0.45876852] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.7536295  0.349701   0.09387544 0.1690418  0.04463288 0.27530596\n",
      " 0.40140927] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7848232  0.3517596  0.1254989  0.18576401 0.05265149 0.3078157\n",
      " 0.4606088 ] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.79496217 0.29977968 0.12628895 0.17081812 0.0390014  0.275912\n",
      " 0.47400063] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.7410051  0.32211193 0.11971534 0.18954155 0.04433972 0.27148473\n",
      " 0.44040415] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.83396155 0.35179442 0.08242977 0.13028559 0.03820061 0.30455223\n",
      " 0.41124976] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.76942825 0.36326176 0.1346444  0.18299046 0.06383757 0.34293312\n",
      " 0.43180174] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7417869  0.36138386 0.14942873 0.19841549 0.07486423 0.33971125\n",
      " 0.42736012] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7561827  0.3524564  0.12818018 0.18365975 0.06286599 0.3133481\n",
      " 0.42153633] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7285338  0.32917485 0.08836854 0.1576011  0.03897322 0.26945856\n",
      " 0.3704441 ] Actual Label: [1 0 1 1 0 0 0]\n",
      "Prediction: [0.7671294  0.34921    0.10903064 0.16925238 0.0485253  0.30660337\n",
      " 0.41579592] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7339964  0.34044152 0.13195935 0.19204512 0.05876871 0.30247948\n",
      " 0.42330012] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.80266356 0.3582279  0.08331899 0.13326259 0.04209665 0.31578344\n",
      " 0.3825225 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7976841  0.33214232 0.1108053  0.15466246 0.0440207  0.31045198\n",
      " 0.42878088] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7665948  0.3475037  0.12321419 0.1704995  0.05862654 0.32138047\n",
      " 0.41257936] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7543196  0.32337698 0.14576764 0.19412592 0.05546803 0.30036592\n",
      " 0.45524502] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7915583  0.3200763  0.09023158 0.15883395 0.03147192 0.2550455\n",
      " 0.44206885] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.73630637 0.3537787  0.12652567 0.18591896 0.06141588 0.3173279\n",
      " 0.40882626] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.82377577 0.3686495  0.09367353 0.13873763 0.04475768 0.34184918\n",
      " 0.4106728 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7855558  0.33345863 0.08887469 0.1492019  0.03764448 0.27724704\n",
      " 0.40550113] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7570433  0.33609065 0.13158666 0.19948538 0.05424891 0.28047562\n",
      " 0.45954692] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.7921034  0.33212176 0.07746296 0.1450418  0.03396542 0.2515931\n",
      " 0.40378833] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.8047826  0.35974115 0.09374306 0.14333211 0.04144218 0.3332855\n",
      " 0.40557146] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.76692945 0.3328623  0.08679721 0.15232097 0.03929178 0.26612067\n",
      " 0.39088306] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76952285 0.33247593 0.10001489 0.15579174 0.04199556 0.29311797\n",
      " 0.4021294 ] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.79663545 0.36861795 0.09841742 0.16199774 0.04842073 0.30874363\n",
      " 0.42298284] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.84667027 0.36588392 0.07925605 0.12351095 0.03358176 0.33921322\n",
      " 0.42085603] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.8441704  0.30894667 0.09900004 0.13714054 0.03460146 0.27622288\n",
      " 0.45972183] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.7816355  0.35690227 0.10020581 0.15211362 0.04639118 0.32814246\n",
      " 0.39664474] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7691905  0.3365032  0.14628142 0.18729635 0.06197252 0.3194328\n",
      " 0.44911838] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.78583467 0.37386975 0.10773865 0.16015442 0.05320673 0.343185\n",
      " 0.4201881 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7856483  0.35850045 0.09240896 0.14374135 0.04643065 0.32224447\n",
      " 0.3810994 ] Actual Label: [1 1 0 1 0 0 1]\n",
      "Prediction: [0.7548413  0.3678788  0.10673469 0.16904177 0.05496558 0.32359922\n",
      " 0.39334795] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.781453   0.31166506 0.12351014 0.17724645 0.04274204 0.27388525\n",
      " 0.46269977] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.76639616 0.36666027 0.1079822  0.16142067 0.05557041 0.33586276\n",
      " 0.39070743] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.81819797 0.2945333  0.09680216 0.14207326 0.02746497 0.26897895\n",
      " 0.45450345] Actual Label: [1 0 1 0 0 1 1]\n",
      "Prediction: [0.7689577  0.3473388  0.0882761  0.16081889 0.03728686 0.28117615\n",
      " 0.40867358] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.79697806 0.39184487 0.10606521 0.15697725 0.05977517 0.35636786\n",
      " 0.42072693] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.74583673 0.3439476  0.09098385 0.15003888 0.041527   0.3007128\n",
      " 0.38816208] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77568394 0.35361978 0.09254922 0.15247716 0.04383274 0.30467072\n",
      " 0.3920114 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7552164  0.34167945 0.10121717 0.1643117  0.04506462 0.29300383\n",
      " 0.39924717] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7895616  0.362765   0.07437404 0.12969372 0.03432325 0.32086876\n",
      " 0.38176665] Actual Label: [1 0 1 1 1 1 0]\n",
      "Prediction: [0.70888704 0.34236664 0.11953199 0.20117493 0.05570865 0.27271128\n",
      " 0.4148804 ] Actual Label: [0 1 0 0 0 0 0]\n",
      "Prediction: [0.7943744  0.36533144 0.092902   0.14585565 0.04190764 0.33772388\n",
      " 0.39803267] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7586469  0.35690597 0.11736718 0.17051302 0.05619483 0.32748443\n",
      " 0.41132382] Actual Label: [0 1 0 1 1 1 0]\n",
      "Prediction: [0.7880801  0.3382859  0.11308236 0.15897879 0.04749437 0.31325847\n",
      " 0.42826194] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7563244  0.37780574 0.11243045 0.16892076 0.06187519 0.33947033\n",
      " 0.40838054] Actual Label: [1 0 1 0 0 1 1]\n",
      "Prediction: [0.78925484 0.36646727 0.09875689 0.15207626 0.04855812 0.32697797\n",
      " 0.41639018] Actual Label: [0 1 0 0 0 1 1]\n",
      "Prediction: [0.8006474  0.34661275 0.10768741 0.15270759 0.04690039 0.32263947\n",
      " 0.42053148] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.82804686 0.34520206 0.09303646 0.13558845 0.03821325 0.32146728\n",
      " 0.4220783 ] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [0.78687453 0.33779272 0.09915795 0.16954346 0.0418472  0.26488507\n",
      " 0.4407312 ] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.8190857  0.39376944 0.08482698 0.13451852 0.04670304 0.36111063\n",
      " 0.38616   ] Actual Label: [0 1 0 1 1 1 1]\n",
      "Prediction: [0.7315268  0.354553   0.08774791 0.16723868 0.04317339 0.27781945\n",
      " 0.37836602] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77601266 0.36011457 0.09051894 0.14443925 0.04439603 0.3254604\n",
      " 0.37608522] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.727689   0.35588944 0.11708744 0.1894636  0.05595011 0.30187702\n",
      " 0.408599  ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7982076  0.3317343  0.08640828 0.13844632 0.03368556 0.29565352\n",
      " 0.40264967] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.70438    0.35223877 0.11522863 0.20344223 0.05670838 0.2731858\n",
      " 0.4101519 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.8250468  0.31774682 0.10380971 0.14452572 0.03324493 0.3030112\n",
      " 0.454642  ] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [0.7484072  0.37758616 0.13926195 0.19258714 0.08010155 0.3438577\n",
      " 0.41386563] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7974741  0.30944255 0.10413054 0.1517655  0.03538058 0.28027517\n",
      " 0.43722957] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7482879  0.33387256 0.12955035 0.19166775 0.05755872 0.28297877\n",
      " 0.4362267 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7495562  0.3611431  0.09089486 0.17410614 0.04274144 0.27987707\n",
      " 0.40518227] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.83378994 0.40072796 0.07450246 0.12049025 0.04659887 0.36084056\n",
      " 0.36664268] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7328145  0.39852902 0.0935589  0.15787935 0.06269203 0.3498625\n",
      " 0.34354436] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.74693286 0.3944244  0.10574868 0.16781346 0.06095303 0.3606849\n",
      " 0.37404093] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8045161  0.32991347 0.08087266 0.13667127 0.03440683 0.27203593\n",
      " 0.4015547 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.81353873 0.3210372  0.08158173 0.13390628 0.02869499 0.27985677\n",
      " 0.41758764] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7716489  0.35778704 0.10826235 0.17151715 0.05184067 0.30530596\n",
      " 0.4179209 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7163346  0.30595592 0.10155851 0.19669166 0.03592169 0.216152\n",
      " 0.4385109 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7846911  0.33757746 0.08598867 0.14355984 0.03676683 0.28876576\n",
      " 0.39539665] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78164095 0.36632863 0.07926686 0.14151827 0.04152379 0.30555204\n",
      " 0.371367  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.80612236 0.36760926 0.12265952 0.16306265 0.06350657 0.3439277\n",
      " 0.429218  ] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.68374765 0.36218956 0.08518679 0.17887199 0.04684994 0.26726884\n",
      " 0.3542515 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.8144134  0.35132495 0.08755343 0.13627912 0.03527728 0.32617936\n",
      " 0.40977514] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.71496385 0.32983264 0.11225397 0.18304649 0.04781843 0.27795795\n",
      " 0.40046886] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.6841081  0.38366866 0.10989179 0.21072964 0.06750691 0.28495824\n",
      " 0.38765517] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.74513847 0.33198345 0.09947591 0.17220831 0.041612   0.26812208\n",
      " 0.40932322] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.73975766 0.38603577 0.12407044 0.1877459  0.06892131 0.348359\n",
      " 0.40118793] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.817617   0.31425142 0.12520848 0.1613536  0.04031115 0.30381683\n",
      " 0.4761149 ] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.69999385 0.3740315  0.08790511 0.17313273 0.04975189 0.294725\n",
      " 0.35311586] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.75946766 0.3405652  0.11497959 0.17660141 0.05070114 0.29295906\n",
      " 0.42263326] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76018715 0.33265218 0.11191569 0.1873293  0.04609037 0.26141384\n",
      " 0.44604185] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8232115  0.33394507 0.11016195 0.1548721  0.04011592 0.30848825\n",
      " 0.4608844 ] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.7379286  0.37186667 0.11979238 0.19724488 0.06466521 0.30220926\n",
      " 0.41841558] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.77376264 0.345513   0.10004485 0.15828048 0.04441014 0.30239043\n",
      " 0.40477258] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.8040634  0.3262041  0.1060081  0.15155756 0.0400291  0.2997138\n",
      " 0.43404588] Actual Label: [1 0 1 1 0 1 0]\n",
      "Prediction: [0.74724585 0.3587231  0.07699172 0.152771   0.03816434 0.2815357\n",
      " 0.3669074 ] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.70353067 0.36575782 0.13344567 0.21774617 0.06836504 0.29840362\n",
      " 0.4233895 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.80026263 0.39275968 0.10925274 0.15990499 0.05834769 0.36759114\n",
      " 0.41287136] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.73107207 0.33244124 0.09416275 0.16631709 0.04329511 0.2651305\n",
      " 0.3834077 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78651124 0.33658633 0.08823401 0.14568675 0.03721561 0.2886574\n",
      " 0.39966732] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7586522  0.36326936 0.12927249 0.19569461 0.06306595 0.310252\n",
      " 0.44048625] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.80145335 0.32790896 0.11973229 0.15949339 0.04903064 0.3046682\n",
      " 0.43945953] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.79060227 0.34696567 0.10365648 0.15744826 0.04531036 0.3085295\n",
      " 0.41927075] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.74046737 0.37320134 0.0972959  0.17585672 0.0530656  0.2981869\n",
      " 0.389222  ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7533264  0.36076555 0.09923279 0.15906523 0.05459427 0.31057355\n",
      " 0.37377623] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.73209447 0.36027315 0.12703843 0.19289693 0.06631429 0.3097612\n",
      " 0.41055998] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.79904604 0.35544682 0.12915598 0.1732963  0.05685587 0.3340218\n",
      " 0.4506202 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.82614046 0.347403   0.07966651 0.12554641 0.03260079 0.31925103\n",
      " 0.40129247] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8056128  0.31942153 0.08900365 0.13688155 0.03637511 0.27659264\n",
      " 0.4062498 ] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.8158146  0.3535588  0.10174296 0.14860044 0.04385893 0.32522553\n",
      " 0.42859226] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.74576896 0.33251646 0.14848779 0.19390483 0.0623173  0.31403\n",
      " 0.43981686] Actual Label: [0 1 0 0 1 1 1]\n",
      "Prediction: [0.8174333  0.37553832 0.08603594 0.14381316 0.0403048  0.32775566\n",
      " 0.41444713] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.78429735 0.3724243  0.11763588 0.1686167  0.056137   0.35006487\n",
      " 0.42154974] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.80088085 0.3041758  0.09924512 0.15751098 0.0320181  0.2537288\n",
      " 0.45562705] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [0.7612459  0.33281702 0.09310064 0.16009794 0.04039323 0.2702458\n",
      " 0.40118784] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.77910936 0.370931   0.10839529 0.1600288  0.05556128 0.3420681\n",
      " 0.39913023] Actual Label: [0 1 0 1 0 1 1]\n",
      "Prediction: [0.7713092  0.35522753 0.12728107 0.17536107 0.05911237 0.33278766\n",
      " 0.42448547] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.81245136 0.363681   0.09609503 0.14214215 0.04622172 0.3355564\n",
      " 0.40538913] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [0.7487454  0.35652557 0.12289161 0.18035467 0.06393145 0.31396252\n",
      " 0.40625986] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [0.7372966  0.37871104 0.11638834 0.18209685 0.0670052  0.3294047\n",
      " 0.39041537] Actual Label: [1 0 1 0 1 1 0]\n",
      "Prediction: [0.7526479  0.36037123 0.14290567 0.20482922 0.0681375  0.3165099\n",
      " 0.44967347] Actual Label: [1 0 1 1 0 0 0]\n",
      "Prediction: [0.79528075 0.36536312 0.10228176 0.15152285 0.04946807 0.3377135\n",
      " 0.40428388] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7722105  0.37628093 0.1288407  0.18022972 0.06375821 0.35494545\n",
      " 0.42556635] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.6752175  0.38435718 0.12487445 0.2296585  0.07466333 0.2879021\n",
      " 0.40671852] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7550782  0.34063986 0.1136255  0.16798899 0.04760118 0.31264707\n",
      " 0.41705704] Actual Label: [0 0 0 1 1 1 0]\n",
      "Prediction: [0.73588425 0.3584865  0.10376497 0.18342128 0.05148163 0.28485468\n",
      " 0.40458867] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.759135   0.37027416 0.0983601  0.16950193 0.05385826 0.3006693\n",
      " 0.39472467] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.72521603 0.33411056 0.1006797  0.18326885 0.04446381 0.25574058\n",
      " 0.40711465] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7129281  0.3754962  0.13774729 0.20635873 0.07480591 0.33211723\n",
      " 0.40920928] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.791514   0.31515983 0.11057665 0.17199914 0.03804827 0.26318663\n",
      " 0.46446663] Actual Label: [0 1 0 0 0 1 1]\n",
      "Prediction: [0.82603633 0.35649404 0.11717388 0.15712173 0.04877154 0.34106088\n",
      " 0.45553404] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.75639284 0.3660529  0.10200811 0.17542769 0.05251411 0.29713804\n",
      " 0.4058405 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.81112474 0.3324589  0.09774665 0.14107963 0.03913911 0.30781367\n",
      " 0.41786328] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7688447  0.3167299  0.10016754 0.16062121 0.04073181 0.2609759\n",
      " 0.4146857 ] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.75539654 0.3919474  0.10433193 0.16999395 0.06401505 0.33783427\n",
      " 0.38155553] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.737042   0.34211954 0.11375444 0.18089423 0.05415249 0.2858882\n",
      " 0.40591627] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.78171587 0.3131928  0.09439462 0.17011972 0.03335073 0.23479156\n",
      " 0.45222977] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8274153  0.34858823 0.07374824 0.12697989 0.03334038 0.2907657\n",
      " 0.40023756] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.80939823 0.3692028  0.06040328 0.1102225  0.0318998  0.3228147\n",
      " 0.33966962] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.75124556 0.36265498 0.13642156 0.1926672  0.06932481 0.32582805\n",
      " 0.4266021 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7998777  0.38448215 0.08579651 0.13845721 0.04644406 0.34624037\n",
      " 0.38707474] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.74432    0.31227845 0.11665639 0.18296026 0.04004698 0.26678205\n",
      " 0.44372445] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.77624923 0.34261748 0.11243793 0.16931437 0.04720175 0.30424663\n",
      " 0.42843983] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7488736  0.32148165 0.10256019 0.17343606 0.03827032 0.26455823\n",
      " 0.422646  ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.69362026 0.38072702 0.13180539 0.22699426 0.07740799 0.29372752\n",
      " 0.4178262 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.75754756 0.34545517 0.09673195 0.15901384 0.04525183 0.2902595\n",
      " 0.40830275] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77648234 0.37884435 0.07927837 0.14664495 0.04407908 0.31020764\n",
      " 0.3707463 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7860759  0.33151913 0.11782589 0.16106966 0.05328495 0.30063376\n",
      " 0.42081943] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.76762086 0.31663588 0.12832125 0.17377137 0.04857662 0.29386342\n",
      " 0.43754852] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7783509  0.32558832 0.12722173 0.17539406 0.04792943 0.30030376\n",
      " 0.448782  ] Actual Label: [1 1 0 0 1 0 1]\n",
      "Prediction: [0.75634253 0.35436237 0.1215325  0.18614267 0.06104797 0.29742303\n",
      " 0.42434916] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.8197618  0.42018327 0.07668044 0.12608503 0.05549444 0.3760292\n",
      " 0.35189998] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.802207   0.39223364 0.09755008 0.1511178  0.04963997 0.36575544\n",
      " 0.4033395 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7156221  0.3115294  0.07829472 0.17747237 0.03092672 0.20082594\n",
      " 0.403627  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.74959534 0.33800343 0.10311786 0.16807957 0.04788928 0.2811569\n",
      " 0.39885235] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7064065  0.34394175 0.11310738 0.187887   0.05684739 0.28023762\n",
      " 0.38929498] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8588812  0.33319628 0.09481283 0.12843463 0.03542166 0.3151728\n",
      " 0.45253703] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7545206  0.36329317 0.11925842 0.17176555 0.0623133  0.33354342\n",
      " 0.39630538] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.8008124  0.33703658 0.10635009 0.1507686  0.04372663 0.31366014\n",
      " 0.42234966] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76905024 0.35396025 0.11210152 0.17516987 0.0536791  0.30023122\n",
      " 0.42187166] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.80823284 0.39367452 0.07949317 0.1325222  0.04339383 0.35842302\n",
      " 0.37240776] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.69856834 0.35237268 0.12816244 0.2087951  0.06495139 0.28569764\n",
      " 0.41054544] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.7893722  0.32620433 0.09982088 0.16427022 0.03984937 0.26209968\n",
      " 0.4394634 ] Actual Label: [0 0 0 1 0 0 0]\n",
      "Prediction: [0.76922905 0.3354341  0.09199499 0.14491536 0.04031927 0.29359183\n",
      " 0.40846962] Actual Label: [0 0 0 1 1 1 0]\n",
      "Prediction: [0.72603923 0.38549116 0.11096831 0.1756775  0.06725655 0.33849475\n",
      " 0.38148427] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.757013   0.30468717 0.06264398 0.13378759 0.02685457 0.21155712\n",
      " 0.35989505] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.80325866 0.33021605 0.11351269 0.1549465  0.04507995 0.30839404\n",
      " 0.43836063] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.8247167  0.3428322  0.10379194 0.14550796 0.04137712 0.32201973\n",
      " 0.43875766] Actual Label: [0 1 1 0 0 0 0]\n",
      "Prediction: [0.82548946 0.3726734  0.09233142 0.13799617 0.04436508 0.34598622\n",
      " 0.41023794] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7774383  0.39599615 0.07493199 0.13633701 0.04226269 0.33358052\n",
      " 0.41286775] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.80161846 0.37810162 0.09477381 0.14383839 0.0514206  0.34548202\n",
      " 0.3884826 ] Actual Label: [1 0 0 0 1 1 1]\n",
      "Prediction: [0.757111   0.3702272  0.08703901 0.1573894  0.04701228 0.30256948\n",
      " 0.3749255 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7077564  0.37197202 0.12280526 0.20970471 0.06999288 0.2912657\n",
      " 0.4089319 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7531682  0.3382534  0.09669483 0.16827974 0.03952336 0.27933407\n",
      " 0.41008997] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8319952  0.34684822 0.09419867 0.13347885 0.04263176 0.31995213\n",
      " 0.41630965] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.80867493 0.34806302 0.09304371 0.14474323 0.03851743 0.31314322\n",
      " 0.41810563] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7364479  0.36862543 0.09965684 0.16899505 0.05402604 0.30546266\n",
      " 0.40101895] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.73361397 0.35475507 0.13048834 0.19740121 0.0648018  0.3029532\n",
      " 0.4221422 ] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [0.7756226  0.34447488 0.08697923 0.1428965  0.04032549 0.30033967\n",
      " 0.37804353] Actual Label: [0 1 0 1 1 0 1]\n",
      "Prediction: [0.8221242  0.33916733 0.11554173 0.15399301 0.04560582 0.3222699\n",
      " 0.45189855] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.74283534 0.36775064 0.08620666 0.15299886 0.05024789 0.3038266\n",
      " 0.3522468 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8161666  0.32542837 0.09480921 0.13988174 0.03244103 0.30529165\n",
      " 0.4329464 ] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.80954397 0.3514116  0.10016944 0.14418498 0.04635934 0.32408777\n",
      " 0.41018662] Actual Label: [1 0 0 1 0 1 1]\n",
      "Prediction: [0.7501208  0.33682165 0.10790052 0.17883976 0.04636259 0.27550012\n",
      " 0.42098522] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.78220665 0.36507913 0.10040243 0.157573   0.04668899 0.3294808\n",
      " 0.40512106] Actual Label: [1 1 1 0 0 1 1]\n",
      "Prediction: [0.75517505 0.32209185 0.08212215 0.15486537 0.03484203 0.24416952\n",
      " 0.39144173] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.71272457 0.3685094  0.11602322 0.1885607  0.05670093 0.32376945\n",
      " 0.40100408] Actual Label: [0 0 1 0 0 1 1]\n",
      "Prediction: [0.6880363  0.37822983 0.1428256  0.22865579 0.0837433  0.3069033\n",
      " 0.41553822] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.79399127 0.35429204 0.1127161  0.16069584 0.04836654 0.3330872\n",
      " 0.42716795] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.76450235 0.34000283 0.10597293 0.16853708 0.04573322 0.29025713\n",
      " 0.41818282] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7046175  0.38149118 0.12256972 0.19587635 0.07077442 0.3311573\n",
      " 0.3844754 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.76328766 0.34517065 0.1221268  0.17009072 0.05776001 0.31748283\n",
      " 0.41280445] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.77387625 0.34971395 0.10533305 0.17395614 0.04400326 0.29432485\n",
      " 0.43362224] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7608943  0.37109858 0.10169027 0.1606357  0.05796907 0.3229486\n",
      " 0.37873948] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7727834  0.37459016 0.09901699 0.1554218  0.04973843 0.34235567\n",
      " 0.39147392] Actual Label: [1 1 0 1 0 1 0]\n",
      "Prediction: [0.7423725  0.35252887 0.11516993 0.18585753 0.05346264 0.2969407\n",
      " 0.4175079 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7952781  0.3792311  0.07232088 0.13026573 0.03682657 0.32883593\n",
      " 0.37809154] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [0.7407147  0.37946603 0.13307    0.20143437 0.0737917  0.3267459\n",
      " 0.42285207] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.76738733 0.3662957  0.13117386 0.18510349 0.06467167 0.33429626\n",
      " 0.43068966] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.8258487  0.33816597 0.08576886 0.1296252  0.03487678 0.30918092\n",
      " 0.4102045 ] Actual Label: [1 1 1 0 0 1 1]\n",
      "Prediction: [0.75537413 0.35794267 0.13642074 0.18897627 0.06518322 0.32993507\n",
      " 0.4290234 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.79587096 0.372929   0.09050121 0.1428274  0.04737372 0.3328954\n",
      " 0.4100687 ] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7793991  0.38269773 0.09030601 0.15603276 0.04598795 0.33102927\n",
      " 0.39279923] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.77008337 0.36122027 0.12437332 0.17101839 0.06586625 0.332966\n",
      " 0.40796813] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7614838  0.3460878  0.09161724 0.15396574 0.04326609 0.2929016\n",
      " 0.38379097] Actual Label: [1 0 0 1 1 1 1]\n",
      "Prediction: [0.7315846  0.36343408 0.09768003 0.17192006 0.05167006 0.29742962\n",
      " 0.37923315] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7638921  0.36431846 0.12721302 0.18669535 0.06293008 0.32178622\n",
      " 0.43050674] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.70099866 0.36977416 0.10207107 0.1872501  0.05637917 0.29399097\n",
      " 0.37561074] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7611377  0.33721772 0.14082134 0.18903817 0.06152702 0.30858538\n",
      " 0.44295898] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.814006   0.3344313  0.11738143 0.16624121 0.04421278 0.3000602\n",
      " 0.46828908] Actual Label: [0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds:\n",
    "    predictions = model_vgg.predict(images)  # Only pass image data\n",
    "    #print(predictions[:1])\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
