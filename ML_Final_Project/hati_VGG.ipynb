{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"datacomplete\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get filepaths\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/2_Semester/ML/Assignments/machine_learning/ML_Final_Project/labeled_train.csv\")\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df.sample(n=3000, random_state=42)\n",
    "\n",
    "filenames = df[\"filename\"]\n",
    "# convert each string in the DataFrame to a list\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "\n",
    "# convert each list in the DataFrame to a numpy array\n",
    "df['labels'] = df['labels'].apply(np.array)\n",
    "\n",
    "# store all the arrays in a list\n",
    "labels = df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  700\n",
      "Test Set:  150\n",
      "Validation Set 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['filename'], df['labels'], test_size=0.2)\n",
    "\n",
    "# First split: Splitting into 80% for the temporary training set and 20% for the test set\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(df['filename'], df['labels'], test_size=0.15, random_state=42)\n",
    "\n",
    "# Second split: Splitting the temporary training set into 87.5% for training and 12.5% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "\n",
    "#convert train and test labels to arrays\n",
    "y_train = y_train.apply(np.array).tolist()\n",
    "y_test = y_test.apply(np.array).tolist()\n",
    "y_val = y_val.apply(np.array).tolist()\n",
    "\n",
    "#remove labels\n",
    "y_train = [arr[[1,5,6]] for arr in y_train]\n",
    "y_test = [arr[[1,5,6]] for arr in y_test]\n",
    "y_val = [arr[[1,5,6]] for arr in y_val]\n",
    "\n",
    "print(\"Training Set: \", len(X_train))\n",
    "print(\"Test Set: \", len(X_test))\n",
    "print(\"Validation Set\", len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224\n",
    "channels=3\n",
    "\n",
    "batch_size = 224 # Big enough to measure an F1-score\n",
    "autotune = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "shuffle_buffer_size = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to create data (input for models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from Azure Blob Storage.\"\"\"\n",
    "    blob_client = container_client.get_blob_client(path)\n",
    "    blob_data = blob_client.download_blob().readall()  # Directly read all bytes\n",
    "    return io.BytesIO(blob_data)\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"Loads an image, decodes it to grayscale, resizes, and normalizes it.\"\"\"\n",
    "    # Load image\n",
    "    image_file = load_image(path.numpy().decode('utf-8'))\n",
    "    # Decode the image to grayscale\n",
    "    image_tensor = tf.io.decode_image(image_file.getvalue(), channels=channels)\n",
    "    # Resize the image\n",
    "    image_resized = tf.image.resize(image_tensor, [image_size, image_size])\n",
    "    # Normalize the image data\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "def process_tensor(path, label):\n",
    "    \"\"\"Function to load an image from blob storage, decode, resize, and normalize it.\"\"\"\n",
    "    image_normalized = tf.py_function(load_and_preprocess_image, [path], tf.float32)\n",
    "    # Ensure the shape is set correctly for grayscale\n",
    "    image_normalized.set_shape([image_size, image_size, channels])\n",
    "    return image_normalized, label\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Creates a TensorFlow dataset from filenames and labels.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(process_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "        \n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train)\n",
    "test_ds = create_dataset(X_test, y_test, False)\n",
    "val_ds = create_dataset(X_val, y_val, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):  # Here, take(1) takes the first batch\n",
    "    print(\"Images:\", images.numpy())  # Convert tensor to numpy array and print\n",
    "    print(\"Labels:\", labels.numpy())  # Convert tensor to numpy array and print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features array: (256, 224, 224, 3)\n",
      "Shape of labels array: (256, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 10:50:39.675819: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "#check dataset shape\n",
    "for f, l in train_ds.take(1):\n",
    "    print(\"Shape of features array:\", f.numpy().shape)\n",
    "    print(\"Shape of labels array:\", l.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot one image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_image_from_dataset(dataset, index):\n",
    "    # Take one batch from the dataset\n",
    "    for images, labels in dataset.take(index):\n",
    "        # Assuming the image tensor is in the shape [batch_size, height, width, channels]\n",
    "        # and you need the first image in the batch\n",
    "        first_image = images[0]  # This is a tensor\n",
    "\n",
    "        # Check if the image needs to be squeezed (in case it's a grayscale image with a single channel)\n",
    "        if first_image.shape[-1] == 1:\n",
    "            first_image = tf.squeeze(first_image, axis=-1)\n",
    "        \n",
    "        # Convert tensor to numpy for plotting\n",
    "        first_image_np = first_image.numpy()\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(first_image_np, cmap='gray')\n",
    "        plt.title(f'Label: {labels[0].numpy()}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage with your train_ds dataset\n",
    "plot_first_image_from_dataset(train_ds,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Trained VGG\n",
    "Source: https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "_input = Input((224,224,1)) \n",
    "\n",
    "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
    "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "pool4  = MaxPooling2D((2, 2))(conv10)\n",
    "\n",
    "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
    "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
    "pool5  = MaxPooling2D((2, 2))(conv13)\n",
    "\n",
    "flat   = Flatten()(pool5)\n",
    "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
    "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
    "output = Dense(8, activation=\"sigmoid\")(dense2) #adapted number of outputs and outputfunction\n",
    "\n",
    "vgg16_model  = Model(inputs=_input, outputs=output)\n",
    "\n",
    "LR = 1e-5 #why?\n",
    "EPOCHS = 10 #why?\n",
    "\n",
    "\n",
    "#compile the model\n",
    "vgg16_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LR),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##provide a model summary\n",
    "vgg16_model.summary()\n",
    "\n",
    "#fit the model\n",
    "vgg16_model.fit(\n",
    "    train_ds,\n",
    "    validation_split = 0.2,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get prediction\n",
    "predictions = vgg16_model.predict(train_ds)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, \n",
    "           to_file='vgg.png',\n",
    "           show_shapes=True,\n",
    "           show_dtype=True,\n",
    "           show_layer_names=True,\n",
    "           show_layer_activations=True,\n",
    "           show_trainable=False,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
