{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Trained VGG\n",
    "Source: https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "_input = Input((224,224,1)) \n",
    "\n",
    "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
    "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "pool4  = MaxPooling2D((2, 2))(conv10)\n",
    "\n",
    "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
    "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
    "pool5  = MaxPooling2D((2, 2))(conv13)\n",
    "\n",
    "flat   = Flatten()(pool5)\n",
    "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
    "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
    "output = Dense(1000, activation=\"softmax\")(dense2)\n",
    "\n",
    "vgg16_model  = Model(inputs=_input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Trained VGG\n",
    "Source: https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "img1 = \"../input/flowers-recognition/flowers/tulip/10094729603_eeca3f2cb6.jpg\"\n",
    "img2 = \"../input/flowers-recognition/flowers/dandelion/10477378514_9ffbcec4cf_m.jpg\"\n",
    "img3 = \"../input/flowers-recognition/flowers/sunflower/10386540696_0a95ee53a8_n.jpg\"\n",
    "img4 = \"../input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg\"\n",
    "imgs = [img1, img2, img3, img4]\n",
    "\n",
    "def _load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img \n",
    "\n",
    "def _get_predictions(_model):\n",
    "    f, ax = plt.subplots(1, 4)\n",
    "    f.set_size_inches(80, 40)\n",
    "    for i in range(4):\n",
    "        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))\n",
    "    plt.show()\n",
    "    \n",
    "    f, axes = plt.subplots(1, 4)\n",
    "    f.set_size_inches(80, 20)\n",
    "    for i,img_path in enumerate(imgs):\n",
    "        img = _load_image(img_path)\n",
    "        preds  = decode_predictions(_model.predict(img), top=3)[0]\n",
    "        b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color=\"gray\", ax=axes[i])\n",
    "        b.tick_params(labelsize=55)\n",
    "        f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "vgg16_weights = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "vgg16_model = VGG16(weights=vgg16_weights)\n",
    "_get_predictions(vgg16_model)\n",
    "\n",
    "'''\n",
    "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
    "40960/35363 [==================================] - 0s 0us/step\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
