{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "import ast\n",
    "import re\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageStat\n",
    "import matplotlib.pyplot as plt\n",
    "import io  # Used to convert bytes to a file-like object\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Read CSV file\n",
    "df = pd.read_csv(\"labeled_train.csv\")\n",
    "\n",
    "#set up storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"publicdata\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67279\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `container_client` is already defined\n",
    "#blobs = container_client.list_blobs()\n",
    "#for blob in blobs:\n",
    "#    # Check for both the \".jpg\" extension and the \"samples/\" prefix\n",
    "#    if blob.name.endswith(\".jpg\") and blob.name.startswith(\"samples/\"):\n",
    "#        print(blob.name)\n",
    "#        blob_client = container_client.get_blob_client(blob.name)\n",
    "#        blob_data = blob_client.download_blob().readall()  # Using `readall` for simplicity#\n",
    "\n",
    "#        # Create a BytesIO stream with the image data\n",
    "#        image_data = io.BytesIO(blob_data)\n",
    "\n",
    "        # Open the image\n",
    "#        image = Image.open(image_data)\n",
    "        \n",
    "#        # Convert to grayscale for brightness calculation\n",
    "#        grayscale_image = image.convert(\"L\")\n",
    "\n",
    "        # Calculate the average brightness\n",
    "#        pixel_values = np.array(grayscale_image)\n",
    "#        average_brightness = np.mean(pixel_values)\n",
    "\n",
    "#        print(f\"Average Brightness of {blob.name}: {average_brightness}\")\n",
    "        \n",
    "#        average_contrast = np.std(pixel_values)\n",
    "#        \n",
    "#        print(f\"Average contrast of {blob.name}: {average_contrast}\")\n",
    "        \n",
    "        # Display the image using matplotlib\n",
    "#        plt.imshow(image)\n",
    "#        plt.axis('off')  # Hide axes for better visualization\n",
    "#        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing samples/CAM_BACK/n003-2018-01-03-12-03-23+0800__CAM_BACK__1514952316316487.jpg\n",
      "Brightness: 101.80742916666667, Contrast: 53.962410950964895\n",
      "Processing samples/CAM_BACK/n003-2018-01-08-11-30-34+0800__CAM_BACK__1515382745757583.jpg\n",
      "Brightness: 103.03134166666666, Contrast: 57.394012278962585\n",
      "Processing samples/CAM_BACK/n003-2018-07-12-15-40-35+0800__CAM_BACK__1531383596387543.jpg\n",
      "Brightness: 108.89841805555555, Contrast: 61.68600053224491\n",
      "Processing samples/CAM_BACK/n005-2018-06-14-20-11-03+0800__CAM_BACK__1528979868187591.jpg\n",
      "Brightness: 25.917290972222222, Contrast: 26.339793409508985\n",
      "Processing samples/CAM_BACK/n008-2018-06-04-16-30-00-0400__CAM_BACK__1528144232887570.jpg\n",
      "Brightness: 114.32514097222223, Contrast: 37.80770588544624\n",
      "Processing samples/CAM_BACK/n009-2018-05-08-15-52-41-0400__CAM_BACK__1525809758643363.jpg\n",
      "Brightness: 117.20806944444445, Contrast: 43.433827624402255\n",
      "Processing samples/CAM_BACK/n010-2018-08-27-12-00-23+0800__CAM_BACK__1535342963787283.jpg\n",
      "Brightness: 114.88051666666667, Contrast: 35.300830885873694\n",
      "Processing samples/CAM_BACK/n013-2018-08-20-14-38-24+0800__CAM_BACK__1534747168787005.jpg\n",
      "Brightness: 110.25108958333334, Contrast: 43.97941804594543\n",
      "Processing samples/CAM_BACK/n013-2018-08-21-11-46-25+0800__CAM_BACK__1534823329537005.jpg\n",
      "Brightness: 111.15751666666667, Contrast: 42.04631972466333\n",
      "Processing samples/CAM_BACK/n013-2018-08-28-16-04-27+0800__CAM_BACK__1535443725287005.jpg\n",
      "Brightness: 107.75401458333333, Contrast: 50.95931242103634\n",
      "Processing samples/CAM_BACK/n013-2018-08-29-11-41-15+0800__CAM_BACK__1535514187537005.jpg\n",
      "Brightness: 114.22926458333333, Contrast: 50.67337936180371\n",
      "Processing samples/CAM_BACK_LEFT/n008-2018-05-30-16-31-36-0400__CAM_BACK_LEFT__1527712679297295.jpg\n",
      "Brightness: 113.708225, Contrast: 39.391828264451526\n",
      "Processing samples/CAM_BACK_LEFT/n010-2018-07-05-14-36-33+0800__CAM_BACK_LEFT__1530772754897633.jpg\n",
      "Brightness: 102.47172430555555, Contrast: 43.092269565647584\n",
      "Processing samples/CAM_BACK_LEFT/n010-2018-07-06-11-01-46+0800__CAM_BACK_LEFT__1530847097147633.jpg\n",
      "Brightness: 98.14577569444444, Contrast: 55.67537545527465\n",
      "Processing samples/CAM_BACK_LEFT/n010-2018-08-27-15-10-53+0800__CAM_BACK_LEFT__1535354198047633.jpg\n",
      "Brightness: 109.1388798611111, Contrast: 48.92657878586785\n",
      "Processing samples/CAM_BACK_LEFT/n013-2018-08-02-14-08-14+0800__CAM_BACK_LEFT__1533190807197155.jpg\n",
      "Brightness: 115.76703263888889, Contrast: 36.55671080227104\n",
      "Processing samples/CAM_BACK_LEFT/n013-2018-08-03-14-44-49+0800__CAM_BACK_LEFT__1533278795447155.jpg\n",
      "Brightness: 115.26929930555555, Contrast: 45.937893015348266\n",
      "Processing samples/CAM_BACK_LEFT/n013-2018-08-16-16-15-38+0800__CAM_BACK_LEFT__1534407626447155.jpg\n",
      "Brightness: 108.99670416666666, Contrast: 55.96535787603826\n",
      "Processing samples/CAM_BACK_LEFT/n013-2018-08-27-16-40-42+0800__CAM_BACK_LEFT__1535359525897155.jpg\n",
      "Brightness: 108.51311597222222, Contrast: 49.38715331635845\n",
      "Processing samples/CAM_BACK_LEFT/n015-2018-09-19-11-19-35+0800__CAM_BACK_LEFT__1537327456197423.jpg\n",
      "Brightness: 119.20228194444445, Contrast: 48.760000371017426\n",
      "Processing samples/CAM_BACK_LEFT/n016-2018-07-10-16-55-57+0800__CAM_BACK_LEFT__1531214187897243.jpg\n",
      "Brightness: 111.84006388888889, Contrast: 46.19956172707374\n",
      "Processing samples/CAM_BACK_RIGHT/n003-2018-01-04-11-23-25+0800__CAM_BACK_RIGHT__1515036641194368.jpg\n",
      "Brightness: 109.18558819444445, Contrast: 48.528324111284334\n",
      "Processing samples/CAM_BACK_RIGHT/n008-2018-05-21-11-06-59-0400__CAM_BACK_RIGHT__1526915734627813.jpg\n",
      "Brightness: 110.26893402777777, Contrast: 46.06976709796703\n",
      "Processing samples/CAM_BACK_RIGHT/n008-2018-05-30-15-20-59-0400__CAM_BACK_RIGHT__1527708173277813.jpg\n",
      "Brightness: 108.09189375, Contrast: 46.45578796447029\n",
      "Processing samples/CAM_BACK_RIGHT/n008-2018-05-30-16-31-36-0400__CAM_BACK_RIGHT__1527713376627813.jpg\n",
      "Brightness: 111.38928819444445, Contrast: 40.99110901032213\n",
      "Processing samples/CAM_BACK_RIGHT/n013-2018-08-02-13-54-05+0800__CAM_BACK_RIGHT__1533189734678054.jpg\n",
      "Brightness: 113.0766173611111, Contrast: 50.952065926133834\n",
      "Processing samples/CAM_BACK_RIGHT/n013-2018-08-27-11-35-10+0800__CAM_BACK_RIGHT__1535341306278054.jpg\n",
      "Brightness: 126.09784930555556, Contrast: 43.012445548250106\n",
      "Processing samples/CAM_BACK_RIGHT/n014-2018-06-25-21-03-46-0400__CAM_BACK_RIGHT__1529975550278469.jpg\n",
      "Brightness: 67.78740833333333, Contrast: 47.55059767768946\n",
      "Processing samples/CAM_BACK_RIGHT/n015-2018-09-13-15-25-57+0800__CAM_BACK_RIGHT__1536824126277893.jpg\n",
      "Brightness: 114.74460694444444, Contrast: 37.3394111600071\n",
      "Processing samples/CAM_BACK_RIGHT/n016-2018-07-06-12-06-18+0800__CAM_BACK_RIGHT__1530850955877917.jpg\n",
      "Brightness: 110.97808611111111, Contrast: 47.87140053545454\n",
      "Processing samples/CAM_FRONT/n006-2018-09-17-12-15-45-0400__CAM_FRONT__1537201092012482.jpg\n",
      "Brightness: 112.36834861111112, Contrast: 41.89689763933234\n",
      "Processing samples/CAM_FRONT/n008-2018-03-14-15-16-29-0400__CAM_FRONT__1521055565282267.jpg\n",
      "Brightness: 108.00678541666667, Contrast: 52.059779251968365\n",
      "Processing samples/CAM_FRONT/n008-2018-05-21-11-06-59-0400__CAM_FRONT__1526915374762465.jpg\n",
      "Brightness: 112.92115625, Contrast: 40.154117744728644\n",
      "Processing samples/CAM_FRONT/n008-2018-09-18-14-18-33-0400__CAM_FRONT__1537294833612404.jpg\n",
      "Brightness: 114.75928541666667, Contrast: 37.769357530873194\n",
      "Processing samples/CAM_FRONT/n009-2018-09-12-09-59-51-0400__CAM_FRONT__1536761961012656.jpg\n",
      "Brightness: 106.32606944444444, Contrast: 52.95446372797481\n",
      "Processing samples/CAM_FRONT/n013-2018-08-01-16-46-39+0800__CAM_FRONT__1533113758512407.jpg\n",
      "Brightness: 98.6302798611111, Contrast: 62.18487388149781\n",
      "Processing samples/CAM_FRONT/n013-2018-08-20-14-38-24+0800__CAM_FRONT__1534747862612407.jpg\n",
      "Brightness: 112.28912638888889, Contrast: 44.47084593164034\n",
      "Processing samples/CAM_FRONT/n016-2018-07-04-10-44-39+0800__CAM_FRONT__1530672741162515.jpg\n",
      "Brightness: 101.36461527777777, Contrast: 60.37088419492453\n",
      "Processing samples/CAM_FRONT_LEFT/n010-2018-09-17-15-57-10+0800__CAM_FRONT_LEFT__1537171282504509.jpg\n",
      "Brightness: 111.18120208333333, Contrast: 40.41963890926038\n",
      "Processing samples/CAM_FRONT_LEFT/n013-2018-08-16-16-15-38+0800__CAM_FRONT_LEFT__1534408311904825.jpg\n",
      "Brightness: 118.30929375, Contrast: 46.798482768777276\n",
      "Processing samples/CAM_FRONT_LEFT/n013-2018-08-29-14-19-16+0800__CAM_FRONT_LEFT__1535524658904825.jpg\n",
      "Brightness: 111.13954791666667, Contrast: 40.75654648323464\n",
      "Processing samples/CAM_FRONT_LEFT/n013-2018-09-03-14-54-42+0800__CAM_FRONT_LEFT__1535958018154825.jpg\n",
      "Brightness: 111.35282291666667, Contrast: 44.22042418719015\n",
      "Processing samples/CAM_FRONT_LEFT/n013-2018-09-04-13-30-50+0800__CAM_FRONT_LEFT__1536039168104825.jpg\n",
      "Brightness: 108.21960833333333, Contrast: 54.87185966678223\n",
      "Processing samples/CAM_FRONT_RIGHT/n004-2018-01-04-11-05-42+0800__CAM_FRONT_RIGHT__1515035386214952.jpg\n",
      "Brightness: 105.76757291666667, Contrast: 62.03530854378945\n",
      "Processing samples/CAM_FRONT_RIGHT/n005-2018-06-14-20-11-03+0800__CAM_FRONT_RIGHT__1528978813270418.jpg\n",
      "Brightness: 7.5807263888888885, Contrast: 13.08302913341144\n",
      "Processing samples/CAM_FRONT_RIGHT/n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915251619956.jpg\n",
      "Brightness: 116.23480069444444, Contrast: 34.439328191368354\n",
      "Processing samples/CAM_FRONT_RIGHT/n013-2018-08-27-14-41-26+0800__CAM_FRONT_RIGHT__1535352274870176.jpg\n",
      "Brightness: 110.06709375, Contrast: 47.952465864191886\n",
      "Processing samples/CAM_FRONT_RIGHT/n013-2018-08-27-15-47-08+0800__CAM_FRONT_RIGHT__1535356254370176.jpg\n",
      "Brightness: 108.30065902777778, Contrast: 54.06499244077666\n",
      "Processing samples/CAM_FRONT_RIGHT/n015-2018-09-05-12-12-46+0800__CAM_FRONT_RIGHT__1536121409120339.jpg\n",
      "Brightness: 111.22475208333333, Contrast: 48.07932087216722\n",
      "Processing samples/CAM_FRONT_RIGHT/n016-2018-07-10-11-22-35+0800__CAM_FRONT_RIGHT__1531193197170471.jpg\n",
      "Brightness: 106.34419652777778, Contrast: 49.57350458886771\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate average brightness\n",
    "def calculate_brightness(image):\n",
    "    grayscale_image = image.convert(\"L\")\n",
    "    pixel_values = np.array(grayscale_image)\n",
    "    return np.mean(pixel_values)\n",
    "\n",
    "# Function to calculate contrast\n",
    "def calculate_contrast(image):\n",
    "    grayscale_image = image.convert(\"L\")\n",
    "    stat = ImageStat.Stat(grayscale_image)\n",
    "    return stat.stddev[0]\n",
    "\n",
    "# Create a list to store filenames that need to be removed\n",
    "files_to_remove = []\n",
    "\n",
    "# Process each blob\n",
    "blobs = container_client.list_blobs()\n",
    "for blob in blobs:\n",
    "    if blob.name.endswith(\".jpg\") and blob.name.startswith(\"samples/\"):\n",
    "        print(f\"Processing {blob.name}\")\n",
    "        blob_client = container_client.get_blob_client(blob.name)\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        image_data = io.BytesIO(blob_data)\n",
    "        image = Image.open(image_data)\n",
    "\n",
    "        # Calculate brightness and contrast\n",
    "        brightness = calculate_brightness(image)\n",
    "        contrast = calculate_contrast(image)\n",
    "\n",
    "        print(f\"Brightness: {brightness}, Contrast: {contrast}\")\n",
    "\n",
    "        # Check if the image meets the removal criteria\n",
    "        if brightness < 60 or contrast < 30:\n",
    "            files_to_remove.append(blob.name)\n",
    "\n",
    "# Remove rows from the DataFrame\n",
    "filtered_df = df[~df['filename'].isin(files_to_remove)]\n",
    "\n",
    "# Save the filtered DataFrame back to the CSV file\n",
    "filtered_df.to_csv(\"cleaned_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: ['samples/CAM_BACK/n005-2018-06-14-20-11-03+0800__CAM_BACK__1528979868187591.jpg', 'samples/CAM_FRONT_RIGHT/n005-2018-06-14-20-11-03+0800__CAM_FRONT_RIGHT__1528978813270418.jpg']\n",
      "Remaining rows in CSV: 67277\n"
     ]
    }
   ],
   "source": [
    "print(f\"Files removed: {files_to_remove}\")\n",
    "print(f\"Remaining rows in CSV: {len(filtered_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
