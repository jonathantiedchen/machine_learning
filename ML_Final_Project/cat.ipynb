{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import io  # Used to convert bytes to a file-like object\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "#connection_string = \n",
    "container_name = \"publicdata\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all blobs and process JSON files\n",
    "json_data = {}\n",
    "\n",
    "blobs = container_client.list_blobs()\n",
    "for blob in blobs:\n",
    "    if blob.name.endswith(\".json\"):\n",
    "        # Get the blob content\n",
    "        blob_client = container_client.get_blob_client(blob.name)\n",
    "        blob_content = blob_client.download_blob().content_as_text()\n",
    "\n",
    "        # Convert to JSON and add to the dictionary using the blob's name as the key\n",
    "        json_data[blob.name] = json.loads(blob_content)  # Now storing JSON content as a dictionary\n",
    "\n",
    "# Assigning specific JSON data to variables\n",
    "category = json_data.get(\"v1.0-mini/category.json\", [])\n",
    "sensor = json_data.get(\"v1.0-mini/sensor.json\", {})\n",
    "surface_ann = json_data.get(\"v1.0-mini/surface_ann.json\", {})\n",
    "attribute = json_data.get(\"v1.0-mini/attribute.json\", {})\n",
    "log = json_data.get(\"v1.0-mini/log.json\", {})\n",
    "calibrated_sensor = json_data.get(\"v1.0-mini/calibrated_sensor.json\", {})\n",
    "sample_data = json_data.get(\"v1.0-mini/sample_data.json\", {})\n",
    "sample = json_data.get(\"v1.0-mini/sample.json\", {})\n",
    "ego_pose = json_data.get(\"v1.0-mini/ego_pose.json\", {})\n",
    "object_ann = json_data.get(\"v1.0-mini/object_ann.json\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Clustering and Label Encodeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Category JSON: Group chosen Categories in their Parent Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 650 entries, 0 to 649\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   token                    650 non-null    object        \n",
      " 1   sample_token             650 non-null    object        \n",
      " 2   ego_pose_token           650 non-null    object        \n",
      " 3   calibrated_sensor_token  650 non-null    object        \n",
      " 4   filename                 650 non-null    object        \n",
      " 5   fileformat               650 non-null    object        \n",
      " 6   width                    650 non-null    int64         \n",
      " 7   height                   650 non-null    int64         \n",
      " 8   timestamp                650 non-null    datetime64[ns]\n",
      " 9   is_key_frame             650 non-null    bool          \n",
      " 10  prev                     650 non-null    object        \n",
      " 11  next                     650 non-null    object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), object(8)\n",
      "memory usage: 56.6+ KB\n",
      "None\n",
      "(50, 8)\n",
      "(50, 19)\n"
     ]
    }
   ],
   "source": [
    "#convert into actual json\n",
    "object_ann_json = json.dumps(object_ann, indent=4)\n",
    "sample_data_json = json.dumps(sample_data, indent=4)\n",
    "category_json = json.dumps(category, indent=4)\n",
    "\n",
    "#convert to dataframe for better processing\n",
    "object_ann_df = pd.read_json(object_ann_json)\n",
    "category_df = pd.read_json(category_json)\n",
    "sample_data_df = pd.read_json(sample_data_json)\n",
    "\n",
    "#clustering of categories\n",
    "def transform_category(category_str):\n",
    "    if re.match(r'^human\\.', category_str):\n",
    "        return 'Human'\n",
    "    if re.match(r'^movable_object\\.barrier', category_str):\n",
    "        return 'Barrier'\n",
    "    if re.match(r'^movable_object\\.cone', category_str):\n",
    "        return 'Cone'\n",
    "    if re.match(r'^vehicle\\.bicycle', category_str):\n",
    "        return 'Bike'\n",
    "    if re.match(r'^vehicle\\.motorcycle', category_str):\n",
    "        return 'Motorcycle'\n",
    "    if re.match(r'^vehicle\\.truck', category_str):\n",
    "        return 'Truck'\n",
    "    if re.match(r'^vehicle\\.car', category_str):\n",
    "        return 'Car'\n",
    "    if re.match(r'^movable_object\\.trafficcone', category_str):\n",
    "        return 'Trafficcone'\n",
    "    return None\n",
    "\n",
    "#apply function to the category column -> clustering of chosen categories\n",
    "category_df['name'] = category_df[\"name\"].apply(transform_category)\n",
    "\n",
    "#remove description\n",
    "category_df = category_df.drop(columns=\"description\")\n",
    "\n",
    "#drop rows that are not included in the chosen categories\n",
    "category_df = category_df.dropna(subset=['name'])\n",
    "\n",
    "\n",
    "#merge dataframes based on foreign keys to connect labeling with image data\n",
    "\n",
    "#category_df.to_excel(\"Cat.xlsx\", index=False)\n",
    "# object_ann_df.to_excel(\"Obj.xlsx\", index=False)\n",
    "sample_data_df.to_excel(\"Sample.xlsx\", index=False)\n",
    "\n",
    "obj_cat = pd.merge(object_ann_df, category_df, left_on='category_token', right_on='token', how='inner')\n",
    "obj_cat = obj_cat.dropna(subset=['name'])\n",
    "\n",
    "\n",
    "#remove list of columns from dataframe\n",
    "columns_to_remove = [\"token_x\", \"token_y\", \"category_token\", \"bbox\", \"mask\", \"attribute_tokens\", ]\n",
    "obj_cat = obj_cat.drop(columns=columns_to_remove)\n",
    "\n",
    "#filter so that only key frames are included\n",
    "print(sample_data_df.info())\n",
    "sample_data_df = sample_data_df[sample_data_df[\"is_key_frame\"] == True]\n",
    "\n",
    "#merge with sample data\n",
    "label_data_v1 = pd.merge(sample_data_df, obj_cat, left_on='token', right_on='sample_data_token', how='left')\n",
    "label_data_v1['name'] = label_data_v1['name'].fillna('empty')\n",
    "label_data_v1.to_excel(\"label_data_v1.xlsx\", index=False)\n",
    "\n",
    "#####################\n",
    "label_data_v2 = label_data_v1.groupby(\"filename\")[\"name\"].value_counts().reset_index()\n",
    "#####################\n",
    "#label_data_v2.to_excel(\"label_data_v2.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#remove list of columns from dataframe\n",
    "#columns_to_remove = [\"sample_data_token\", \"sample_token\", \"ego_pose_token\", \"calibrated_sensor_token\", \"fileformat\", \"timestamp\", \"prev\", \"next\"]\n",
    "#label_data_v2 = label_data_v1.drop(columns=columns_to_remove)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dummies = pd.get_dummies(label_data_v2['name'])\n",
    "\n",
    "# Join the dummy variables to the main dataframe\n",
    "labeled = pd.concat([label_data_v2, dummies], axis=1)\n",
    "labeled[dummies.columns] = labeled[dummies.columns].astype(int)\n",
    "\n",
    "\n",
    "# Drop the original 'name' column\n",
    "labeled = labeled.drop(['name'], axis=1)\n",
    "\n",
    "labeled = labeled.drop(['empty'], axis=1)\n",
    "\n",
    "labeled = labeled.drop(['count'], axis=1)\n",
    "labeled.to_excel(\"lbl.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Group by 'filename' and aggregate the data\n",
    "labeled = labeled.groupby('filename').agg({\n",
    "    'Human': 'max',\n",
    "    'Barrier': 'max',\n",
    "    'Bike': 'max',\n",
    "    'Motorcycle': 'max',\n",
    "    'Truck': 'max',\n",
    "    'Car': 'max',\n",
    "    'Trafficcone': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "labeled.to_excel(\"labeled.xlsx\", index=False)\n",
    "print(labeled.shape)\n",
    "\n",
    "#Test shows: currently issue that Images with no annotation of the chosen categories are not included in the labeled dataframe\n",
    "test = pd.merge(sample_data_df, labeled, on=\"filename\", how='left')\n",
    "test.to_excel(\"test.xlsx\", index=False)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing categories that are out-of-scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove unnecessary items from object_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
