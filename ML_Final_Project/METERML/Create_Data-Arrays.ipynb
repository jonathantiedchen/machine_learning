{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCLAIMER: This Notebook can not be executed as it need to connect to the Azure Storage Account used to store the images. It solely serves as demonstraion how the .npy files were created by extracting the file from Azure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import time\n",
    "from keras.models import load_model\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "connection_string = \"<key>\"\n",
    "container_name = \"meterml\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "channels = 3\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"Fetches image data from Azure Blob Storage.\"\"\"\n",
    "    try:\n",
    "        # Create a blob service client\n",
    "        blob_service_client = BlobServiceClient(account_url=\"https://<account_name>.blob.core.windows.net\", credential=\"<account_key>\")\n",
    "        blob_client = container_client.get_blob_client(image_path)\n",
    "\n",
    "        # Download the blob's contents as bytes\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        \n",
    "        return blob_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching image from Azure: {e}\")\n",
    "        # Return a default image or handle the error appropriately\n",
    "        return tf.zeros((image_size, image_size, channels), dtype=tf.uint8).numpy()\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"Loads an image, decodes it to grayscale, resizes, and normalizes it.\"\"\"\n",
    "    # Load image\n",
    "    image_file = load_image(path)\n",
    "    # Decode the image to grayscale\n",
    "    image_tensor = tf.io.decode_image(image_file, channels=channels)\n",
    "    # Resize the image\n",
    "    image_resized = tf.image.resize(image_tensor, [image_size, image_size])\n",
    "    # Normalize the image data\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized.numpy()\n",
    "\n",
    "def create_data_lists(filenames, labels):\n",
    "    \"\"\"Creates lists of images and labels.\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for path, label in zip(filenames, labels):\n",
    "        image = load_and_preprocess_image(path)\n",
    "        X.append(image)\n",
    "        y.append(label)\n",
    "    \n",
    "    X_train = np.array(X)\n",
    "    y_train = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files to get filepaths and labels \n",
    "df_train= pd.read_csv(\"FINAL_METER_ML_train_2000.csv\")\n",
    "df_val = pd.read_csv(\"FINAL_METER_ML_val.csv\")\n",
    "df_test = pd.read_csv(\"FINAL_METER_ML_test.csv\")\n",
    "\n",
    "# convert each string in the DataFrame to a list\n",
    "df_train['Label'] = df_train['Label'].apply(ast.literal_eval).apply(np.array)\n",
    "df_val['Label'] = df_val['Label'].apply(ast.literal_eval).apply(np.array)\n",
    "df_test['Label'] = df_test['Label'].apply(ast.literal_eval).apply(np.array)\n",
    "\n",
    "#define the test/train split in own arrays for images and labels\n",
    "X_train = df_train['Image_Folder']\n",
    "X_val = df_val['Image_Folder']\n",
    "X_test = df_test['Image_Folder']\n",
    "\n",
    "y_train = np.array(df_train['Label']).tolist()\n",
    "y_val = np.array(df_val['Label']).tolist()\n",
    "y_test = np.array(df_test['Label']).tolist()\n",
    "\n",
    "#creaet the image arrays by retrieving the image information from azure\n",
    "X_train, y_train = create_data_lists(X_train, y_train)\n",
    "X_val, y_val = create_data_lists(X_val, y_val)\n",
    "X_test, y_test = create_data_lists(X_test, y_test)\n",
    "\n",
    "# Save the array to a file to later use in models\n",
    "np.save('x_train.npy', X_train)\n",
    "np.save('x_test.npy', X_test)\n",
    "np.save('x_val.npy', X_val)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
