{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "- check learning rates\n",
    "- check early stopping\n",
    "- check callbacks\n",
    "- check corect loss functions\n",
    "- train last layer\n",
    "- make vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "#from tensorflow.keras.layers import Dense, Flatten\n",
    "#from tensorflow.keras.models import Model, Sequential\n",
    "#from keras.layers import MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
    "#from keras.models import Model\n",
    "\n",
    "#from keras.layers import MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
    "#from keras.models import Model\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"meterml\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CAFOs',\n",
       " 1: 'Landfills',\n",
       " 2: 'Mines',\n",
       " 3: 'Negative',\n",
       " 4: 'ProcessingPlants',\n",
       " 5: 'RefineriesAndTerminals',\n",
       " 6: 'WWTreatment'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get filepaths\n",
    "df = pd.read_csv(\"METER_ML_test.csv\")\n",
    "\n",
    "#create dictionary with labels and encoded labels\n",
    "unique_types = df['Type'].unique()\n",
    "unique_type_encoded = df['Type_encoded'].unique()\n",
    "\n",
    "type_dict = {}\n",
    "\n",
    "for i in range(len(unique_types)):\n",
    "    type_dict[unique_type_encoded[i]] = unique_types[i]\n",
    "\n",
    "sorted_type_dict = dict(sorted(type_dict.items()))\n",
    "\n",
    "sorted_type_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions \n",
    "- create data (input for models)\n",
    "- plot accuracy and loss of models\n",
    "- metrices\n",
    "- print dataset\n",
    "- print evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224\n",
    "channels=3\n",
    "autotune = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "\n",
    "def data_split(df):\n",
    "    \"\"\"Splits and returns the dataset into training, validation, and test\"\"\"\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(df['Image_Folder'], df['Type_encoded'], test_size=0.15, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)\n",
    "    #convert labels to array\n",
    "    y_train = np.array(y_train).tolist()\n",
    "    y_val = np.array(y_val).tolist()\n",
    "    y_test = np.array(y_test).tolist()\n",
    "    #print number of observations per datasets\n",
    "    print(\"Nr. Training:\",len(X_train),\"Nr. Validation:\",len(X_val),\"Nr. Test:\",len(X_test))\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Load an image from Azure Blob Storage.\"\"\"\n",
    "    blob_client = container_client.get_blob_client(path)\n",
    "    blob_data = blob_client.download_blob().readall()  # Directly read all bytes\n",
    "    \n",
    "    return io.BytesIO(blob_data)\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"Loads an image, decodes it to grayscale, resizes, and normalizes it.\"\"\"\n",
    "    # Load image\n",
    "    image_file = load_image(path.numpy().decode('utf-8'))\n",
    "    # Decode the image to grayscale\n",
    "    image_tensor = tf.io.decode_image(image_file.getvalue(), channels=channels)\n",
    "    # Resize the image\n",
    "    image_resized = tf.image.resize(image_tensor, [image_size, image_size])\n",
    "    # Normalize the image data\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "def process_tensor(path, label):\n",
    "    \"\"\"Function to load an image from blob storage, decode, resize, and normalize it.\"\"\"\n",
    "    image_normalized = tf.py_function(load_and_preprocess_image, [path], tf.float32)\n",
    "    # Ensure the shape is set correctly for grayscale\n",
    "    image_normalized.set_shape([image_size, image_size, channels])\n",
    "    return image_normalized, label\n",
    "\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Creates a TensorFlow dataset from filenames and labels.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(process_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #shuffle the data when it is the training dataset\n",
    "    if is_training:\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "    #creates batches    \n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def plot_history(model):\n",
    "    \"\"\"Plots the accuracy and loss of the inputted model.\"\"\"\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model.history['accuracy'])\n",
    "    plt.plot(model.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_predictions(model, ds):\n",
    "    \"\"\"Predictions based on test dataset.\"\"\"\n",
    "    #predict\n",
    "    for images, labels in ds:\n",
    "        predictions = model.predict(images)  # Only pass image data\n",
    "     #print(predictions[:1])\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "        break\n",
    "    \n",
    "def create_all_datasets(X_train, X_val, X_test, y_train, y_val, y_test ):\n",
    "    \"\"\"Creates train, test, and val datasets by calling the create_dataset function each.\"\"\"\n",
    "    train_ds = create_dataset(X_train, y_train)\n",
    "    test_ds = create_dataset(X_test, y_test, False)\n",
    "    val_ds = create_dataset(X_val, y_val, False)\n",
    "    \n",
    "    return train_ds, test_ds, val_ds\n",
    "\n",
    "def print_dataset(dataset):\n",
    "    \"\"\"Print the plain dataset.\"\"\"\n",
    "    for images, labels in dataset.take(1):  # Here, take(1) takes the first batch\n",
    "        print(\"Images:\", images.numpy())  # Convert tensor to numpy array and print\n",
    "        print(\"Labels:\", labels.numpy())  # Convert tensor to numpy array and print\n",
    "        \n",
    "def plot_model(model): \n",
    "    \"\"\"Plot model with predefined arguments.\"\"\"\n",
    "    plot_model(model, \n",
    "            to_file='vgg.png',\n",
    "            show_shapes=True,\n",
    "            show_dtype=True,\n",
    "            show_layer_names=True,\n",
    "            show_layer_activations=True,\n",
    "            show_trainable=False)\n",
    "    \n",
    "\n",
    "def evaluate_cnn(model, data, labels):\n",
    "    \"\"\"\n",
    "    Evaluates a CNN model on given data and labels.\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The trained CNN model.\n",
    "        data (np.array): Input data for evaluation (images).\n",
    "        labels (np.array): True labels for the data.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Making predictions\n",
    "    predictions = model.predict(data)\n",
    "    predicted_classes = tf.argmax(predictions, axis=1)\n",
    "    true_classes = tf.argmax(labels, axis=1)\n",
    "    \n",
    "    # Calculating metrics\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "    recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your CNN model and you have `test_images` and `test_labels`\n",
    "# results = evaluate_cnn(model, test_images, test_labels)\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. Training: 692 Nr. Validation: 149 Nr. Test: 149\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_split(df)\n",
    "    \n",
    "train_ds, test_ds, val_ds = create_all_datasets(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2: \n",
    "https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "def create_mobilenetv2_model():\n",
    "    # Load MobileNetV2 from Keras Applications\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Adding custom layers on top of MobileNetV2\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)  # Dropout for regularization\n",
    "    predictions = Dense(7, activation='softmax')(x)  # Final layer with softmax activation for classification\n",
    "\n",
    "    # Construct the full model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=\"adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_mnv2 = create_mobilenetv2_model()\n",
    "\n",
    "# Assuming train_ds, X_test, y_test are properly defined\n",
    "history = model_mnv2.fit(train_ds,\n",
    "                      validation_data = val_ds, \n",
    "                      epochs=10)\n",
    "\n",
    "plot_history(history)\n",
    "print_predictions(model_mnv2, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception.v3: \n",
    "https://towardsdatascience.com/understanding-the-amazon-rainforest-with-multi-label-classification-vgg-19-inceptionv3-5084544fb655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inception v3\n",
    "inceptionv3 = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in inceptionv3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom layers\n",
    "x = inceptionv3.output\n",
    "x = GlobalAveragePooling2D()(x)  # Ensure this reduces all spatial dimensions\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output = Dense(7, activation=\"softmax\")(x)  # Adjust the number of output units to match the number of classes\n",
    "\n",
    "# Creating the final model\n",
    "inceptionv3_model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "inceptionv3_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Set up the model checkpoint\n",
    "model_checkpoint = ModelCheckpoint('inceptionv3_model.keras', monitor=\"val_accuracy\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Assuming train_ds, X_test, y_test are properly defined\n",
    "history = inceptionv3_model.fit(train_ds,\n",
    "                      validation_data = val_ds, \n",
    "                      epochs=10, \n",
    "                      callbacks=[model_checkpoint])\n",
    "\n",
    "plot_history(history)\n",
    "print_predictions(inceptionv3_model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 with transfer learning: \n",
    "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(7, activation='softmax')\n",
    "\n",
    "vgg16_tf_model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "vgg16_tf_model.compile(\n",
    "optimizer='adam',\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', \n",
    "                   mode='max', \n",
    "                   patience=5,  \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "history = vgg16_tf_model.fit(train_ds, \n",
    "                        validation_data = val_ds, \n",
    "                        epochs=10, \n",
    "                        batch_size=32, \n",
    "                        callbacks=[es])\n",
    "\n",
    "plot_history(history)\n",
    "print_predictions(vgg16_tf_model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50: \n",
    "https://datagen.tech/guides/computer-vision/resnet-50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "rn50_base = tf.keras.applications.ResNet50(\n",
    "    weights = \"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "for each_layer in rn50_base.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "resnet_model.add(rn50_base)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "resnet_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "resnet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = resnet_model.fit(train_ds, validation_data = val_ds, epochs=10)\n",
    "\n",
    "plot_history(resnet_model)\n",
    "print_predictions(resnet_model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-trained VGG16\n",
    "Source: https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input((224,224,1)) \n",
    "\n",
    "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
    "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "pool1  = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "pool2  = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "pool3  = MaxPooling2D((2, 2))(conv7)\n",
    "\n",
    "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "pool4  = MaxPooling2D((2, 2))(conv10)\n",
    "\n",
    "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
    "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
    "pool5  = MaxPooling2D((2, 2))(conv13)\n",
    "\n",
    "flat   = Flatten()(pool5)\n",
    "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
    "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
    "output = Dense(7, activation=\"softmax\")(dense2) #adapted number of outputs and outputfunction\n",
    "\n",
    "vgg16_model  = Model(inputs=_input, outputs=output)\n",
    "\n",
    "LR = 1e-5 #why?\n",
    "\n",
    "#compile the model\n",
    "vgg16_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LR),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##provide a model summary\n",
    "vgg16_model.summary()\n",
    "\n",
    "#fit the model\n",
    "vgg16_model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "plot_history(vgg16_model)\n",
    "print_predictions(vgg16_model, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
