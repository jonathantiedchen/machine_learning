{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storage\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=mlfinalexam5505462853;AccountKey=0c40lghglG5/GlNK9yujDQAgo38GKoS2I3DeC/g22hwAEIFANKpmC/TqOpRk4RCT1DbfNiHBFt72+AStB+PfUA==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"meterml\"\n",
    "\n",
    "#create client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Image_Folder   Type  Type_encoded\n",
      "0  samples/test_images/35.17852862_-79.99927082.png  CAFOs             0\n",
      "1      samples/test_images/47.863317_-92.810639.png  CAFOs             0\n",
      "2      samples/test_images/33.440833_-85.435833.png  CAFOs             0\n",
      "3  samples/test_images/45.12488405_-94.24194995.png  CAFOs             0\n",
      "4  samples/test_images/45.33317705_-94.50533971.png  CAFOs             0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'CAFOs',\n",
       " 1: 'Landfills',\n",
       " 2: 'Mines',\n",
       " 3: 'Negative',\n",
       " 4: 'ProcessingPlants',\n",
       " 5: 'RefineriesAndTerminals',\n",
       " 6: 'WWTreatment'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get filepaths\n",
    "df = pd.read_csv(\"METER_ML_test.csv\")\n",
    "print(df.head())\n",
    "\n",
    "#create dictionary with labels and encoded labels\n",
    "unique_types = df['Type'].unique()\n",
    "unique_type_encoded = df['Type_encoded'].unique()\n",
    "\n",
    "type_dict = {}\n",
    "\n",
    "for i in range(len(unique_types)):\n",
    "    type_dict[unique_type_encoded[i]] = unique_types[i]\n",
    "\n",
    "sorted_type_dict = dict(sorted(type_dict.items()))\n",
    "\n",
    "sorted_type_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "149\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "# First Split:\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(df['Image_Folder'], df['Type_encoded'], test_size=0.15, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42)\n",
    "\n",
    "\n",
    "y_train = np.array(y_train).tolist()\n",
    "y_val = np.array(y_val).tolist()\n",
    "y_test = np.array(y_test).tolist()\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=224\n",
    "channels=3\n",
    "\n",
    "batch_size = 224 # Big enough to measure an F1-score\n",
    "autotune = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "shuffle_buffer_size = 1024 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions \n",
    "- create data (input for models)\n",
    "- plot accuracy and loss of models\n",
    "- metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image from Azure Blob Storage.\"\"\"\n",
    "    blob_client = container_client.get_blob_client(path)\n",
    "    blob_data = blob_client.download_blob().readall()  # Directly read all bytes\n",
    "    return io.BytesIO(blob_data)\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"Loads an image, decodes it to grayscale, resizes, and normalizes it.\"\"\"\n",
    "    # Load image\n",
    "    image_file = load_image(path.numpy().decode('utf-8'))\n",
    "    # Decode the image to grayscale\n",
    "    image_tensor = tf.io.decode_image(image_file.getvalue(), channels=channels)\n",
    "    # Resize the image\n",
    "    image_resized = tf.image.resize(image_tensor, [image_size, image_size])\n",
    "    # Normalize the image data\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "def process_tensor(path, label):\n",
    "    \"\"\"Function to load an image from blob storage, decode, resize, and normalize it.\"\"\"\n",
    "    image_normalized = tf.py_function(load_and_preprocess_image, [path], tf.float32)\n",
    "    # Ensure the shape is set correctly for grayscale\n",
    "    image_normalized.set_shape([image_size, image_size, channels])\n",
    "    return image_normalized, label\n",
    "\n",
    "def create_dataset(filenames, labels, is_training=True):\n",
    "    \"\"\"Creates a TensorFlow dataset from filenames and labels.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(process_tensor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.cache()\n",
    "        dataset = dataset.shuffle(buffer_size=1024)\n",
    "        \n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def plot_history(model):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model.history['accuracy'])\n",
    "    plt.plot(model.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_predictions(model, ds):\n",
    "    #predict\n",
    "    for images, labels in ds:\n",
    "        predictions = model.predict(images)  # Only pass image data\n",
    "     #print(predictions[:1])\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            print(\"Prediction:\", pred, \"Actual Label:\", label.numpy())# Print the first prediction\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, y_train)\n",
    "test_ds = create_dataset(X_test, y_test, False)\n",
    "val_ds = create_dataset(X_val, y_val, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):  # Here, take(1) takes the first batch\n",
    "    print(\"Images:\", images.numpy())  # Convert tensor to numpy array and print\n",
    "    print(\"Labels:\", labels.numpy())  # Convert tensor to numpy array and print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2: \n",
    "https://github.com/ashrefm/multi-label-soft-f1/blob/master/Multi-Label%20Image%20Classification%20in%20TensorFlow%202.0.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "\n",
    "model_mnv2 = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    layers.Dense(1024, activation='relu', name='hidden_layer'),\n",
    "    layers.Dense(7, activation='sigmoid', name='output')\n",
    "])\n",
    "\n",
    "model_mnv2.summary()\n",
    "\n",
    "print_predictions(model_mnv2, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception.v3: \n",
    "https://towardsdatascience.com/understanding-the-amazon-rainforest-with-multi-label-classification-vgg-19-inceptionv3-5084544fb655"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Instantiate and compile the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m inceptionv3_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_inception_v3_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Set up the model checkpoint\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minceptionv3_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mcreate_inception_v3_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Creating the final model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minceptionv3\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39moutput)\n\u001b[0;32m---> 21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def create_inception_v3_model():\n",
    "    inceptionv3 = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in inceptionv3.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Adding custom layers\n",
    "    x = inceptionv3.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Ensure this reduces all spatial dimensions\n",
    "    x = Dense(4096, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(7, activation=\"softmax\")(x)  # Adjust the number of output units to match the number of classes\n",
    "\n",
    "    # Creating the final model\n",
    "    model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "inceptionv3_model = create_inception_v3_model()\n",
    "\n",
    "# Set up the model checkpoint\n",
    "model_checkpoint = ModelCheckpoint('inceptionv3_model.keras', monitor=\"val_accuracy\", verbose=1, save_best_only=True)\n",
    "\n",
    "# Assuming train_ds, X_test, y_test are properly defined\n",
    "history = inceptionv3_model.fit(train_ds,\n",
    "                      validation_data = val_ds, \n",
    "                      epochs=10, \n",
    "                      callbacks=[model_checkpoint])\n",
    "\n",
    "plot_history(history)\n",
    "print_predictions(inceptionv3_model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step\n",
      "Prediction: [0.01274665 0.02877691 0.15972051 0.4063261  0.09525526 0.02191788\n",
      " 0.27525672] Actual Label: 6\n",
      "Prediction: [3.9608635e-06 7.5503305e-04 2.1353243e-04 1.2476606e-03 6.6801149e-05\n",
      " 9.9590027e-01 1.8127172e-03] Actual Label: 5\n",
      "Prediction: [0.0459647  0.2145908  0.04191964 0.3156867  0.26957166 0.01276872\n",
      " 0.09949772] Actual Label: 4\n",
      "Prediction: [0.0031893  0.03031961 0.00656269 0.01690817 0.0049908  0.9241715\n",
      " 0.01385791] Actual Label: 5\n",
      "Prediction: [0.3868611  0.10223748 0.01723989 0.2559255  0.17762122 0.00570343\n",
      " 0.0544114 ] Actual Label: 0\n",
      "Prediction: [0.11963693 0.18464087 0.06165045 0.16074783 0.31524956 0.01238855\n",
      " 0.14568576] Actual Label: 4\n",
      "Prediction: [0.00162375 0.1069823  0.04688137 0.7730318  0.03719909 0.00218598\n",
      " 0.03209578] Actual Label: 6\n",
      "Prediction: [0.00623571 0.14008905 0.24893196 0.40581325 0.09949404 0.00954302\n",
      " 0.08989301] Actual Label: 2\n",
      "Prediction: [0.01725106 0.02281215 0.11729892 0.6697174  0.03955499 0.00729092\n",
      " 0.12607452] Actual Label: 0\n",
      "Prediction: [0.01387517 0.15564944 0.03317913 0.70383793 0.07205748 0.00241228\n",
      " 0.01898861] Actual Label: 4\n",
      "Prediction: [5.9190905e-04 5.3016037e-02 1.7796235e-02 7.6238796e-02 1.0427937e-02\n",
      " 7.7259266e-01 6.9336407e-02] Actual Label: 5\n",
      "Prediction: [0.009542   0.47874472 0.2725487  0.12150592 0.09313934 0.00965634\n",
      " 0.01486297] Actual Label: 1\n",
      "Prediction: [0.08675514 0.38520834 0.0233364  0.3526787  0.10684801 0.00927575\n",
      " 0.03589766] Actual Label: 3\n",
      "Prediction: [0.10732674 0.14026874 0.02852483 0.5204309  0.05335634 0.07980837\n",
      " 0.07028398] Actual Label: 0\n",
      "Prediction: [0.02557335 0.1381824  0.08730243 0.54831475 0.06723919 0.0169401\n",
      " 0.11644775] Actual Label: 3\n",
      "Prediction: [0.04942393 0.07284213 0.0225959  0.6657111  0.04650543 0.0131518\n",
      " 0.1297698 ] Actual Label: 3\n",
      "Prediction: [0.00686138 0.01198769 0.00441735 0.6091192  0.03402383 0.02611021\n",
      " 0.3074804 ] Actual Label: 3\n",
      "Prediction: [0.01121474 0.09736398 0.00900395 0.812076   0.04242344 0.00234112\n",
      " 0.02557686] Actual Label: 3\n",
      "Prediction: [0.28138965 0.08436914 0.02401822 0.39721295 0.12041587 0.00967332\n",
      " 0.08292081] Actual Label: 0\n",
      "Prediction: [0.02844469 0.04227412 0.2029292  0.6188377  0.05454824 0.01023627\n",
      " 0.04272962] Actual Label: 3\n",
      "Prediction: [0.02473038 0.08375723 0.18513876 0.5260857  0.08760784 0.01235161\n",
      " 0.08032856] Actual Label: 2\n",
      "Prediction: [0.02623798 0.2278007  0.07898924 0.3279361  0.11058343 0.12528796\n",
      " 0.10316468] Actual Label: 4\n",
      "Prediction: [0.00424399 0.09221397 0.08708034 0.7557969  0.04240419 0.00327485\n",
      " 0.01498575] Actual Label: 3\n",
      "Prediction: [0.02626664 0.06623563 0.68919414 0.08098955 0.07043578 0.01197095\n",
      " 0.05490739] Actual Label: 4\n",
      "Prediction: [0.01404464 0.12237797 0.33602446 0.36367297 0.09507648 0.01105361\n",
      " 0.05774983] Actual Label: 4\n",
      "Prediction: [0.02417003 0.02953136 0.0912074  0.7172492  0.07828162 0.00607285\n",
      " 0.05348759] Actual Label: 3\n",
      "Prediction: [0.00817382 0.05885367 0.04729442 0.80051327 0.05080521 0.00330655\n",
      " 0.03105298] Actual Label: 3\n",
      "Prediction: [0.01370458 0.03578868 0.01995225 0.8289072  0.04155122 0.00406605\n",
      " 0.05603008] Actual Label: 4\n",
      "Prediction: [0.02538817 0.0785716  0.24867477 0.5076714  0.06015888 0.01285789\n",
      " 0.06667726] Actual Label: 1\n",
      "Prediction: [0.07552413 0.07837413 0.04935918 0.55301124 0.11315886 0.03108411\n",
      " 0.09948831] Actual Label: 3\n",
      "Prediction: [0.00835544 0.24852033 0.24638124 0.37050214 0.09921844 0.00247533\n",
      " 0.02454705] Actual Label: 3\n",
      "Prediction: [0.01395564 0.02842047 0.04822177 0.4117492  0.06138169 0.05451136\n",
      " 0.38175997] Actual Label: 3\n",
      "Prediction: [0.00062893 0.04943383 0.02111793 0.21143185 0.01013199 0.562995\n",
      " 0.14426051] Actual Label: 6\n",
      "Prediction: [0.00552113 0.32247645 0.09762619 0.10078939 0.05736823 0.34061348\n",
      " 0.07560512] Actual Label: 6\n",
      "Prediction: [0.05182559 0.10388734 0.03523737 0.58686703 0.10568688 0.02710139\n",
      " 0.08939449] Actual Label: 3\n",
      "Prediction: [0.04330421 0.02853198 0.0350728  0.74259293 0.04814274 0.00558523\n",
      " 0.09677002] Actual Label: 3\n",
      "Prediction: [0.03612212 0.10958928 0.19678567 0.32540008 0.24016507 0.01169838\n",
      " 0.08023939] Actual Label: 3\n",
      "Prediction: [0.23795944 0.11318729 0.067491   0.2794094  0.16260046 0.01344708\n",
      " 0.12590536] Actual Label: 3\n",
      "Prediction: [2.4730794e-04 1.7539037e-02 2.5179575e-03 8.9415766e-02 4.6175541e-03\n",
      " 8.5570025e-01 2.9962122e-02] Actual Label: 5\n",
      "Prediction: [0.02208679 0.0479021  0.09291014 0.6855497  0.02666934 0.02053235\n",
      " 0.10434951] Actual Label: 3\n",
      "Prediction: [0.01589719 0.05504481 0.03494811 0.6444752  0.05944339 0.0502749\n",
      " 0.13991638] Actual Label: 3\n",
      "Prediction: [0.20872428 0.2793073  0.03567636 0.29642794 0.12842803 0.01736019\n",
      " 0.03407595] Actual Label: 0\n",
      "Prediction: [0.07211413 0.0223814  0.05911337 0.24502288 0.14485423 0.02344963\n",
      " 0.43306434] Actual Label: 0\n",
      "Prediction: [0.02093432 0.08333878 0.0376518  0.62671065 0.11957902 0.01290068\n",
      " 0.09888466] Actual Label: 3\n",
      "Prediction: [0.07669444 0.13289441 0.0643295  0.5128819  0.1638895  0.00145234\n",
      " 0.04785791] Actual Label: 0\n",
      "Prediction: [0.01957639 0.04731092 0.28064504 0.42365324 0.08944904 0.01032252\n",
      " 0.12904283] Actual Label: 2\n",
      "Prediction: [0.03329543 0.20111991 0.04844611 0.326482   0.19610243 0.01447928\n",
      " 0.18007478] Actual Label: 4\n",
      "Prediction: [0.0128395  0.06316232 0.04575605 0.7958794  0.03754088 0.00813648\n",
      " 0.03668538] Actual Label: 3\n",
      "Prediction: [0.0048559  0.11861169 0.0585688  0.38056967 0.04374706 0.14091031\n",
      " 0.25273657] Actual Label: 3\n",
      "Prediction: [1.5081484e-05 1.0035256e-03 7.3660724e-04 1.3120766e-03 5.6454235e-05\n",
      " 9.9568862e-01 1.1875762e-03] Actual Label: 5\n",
      "Prediction: [0.01566725 0.10725215 0.25829434 0.3120146  0.08881025 0.03449575\n",
      " 0.18346556] Actual Label: 2\n",
      "Prediction: [0.06584515 0.09557877 0.03967515 0.4973592  0.12496608 0.00654315\n",
      " 0.17003256] Actual Label: 6\n",
      "Prediction: [0.02562532 0.1137892  0.16287336 0.6012953  0.03974715 0.01054936\n",
      " 0.04612037] Actual Label: 3\n",
      "Prediction: [0.0042881  0.01025809 0.02684853 0.39756763 0.07316318 0.0055726\n",
      " 0.48230186] Actual Label: 1\n",
      "Prediction: [0.04861885 0.05384954 0.16342592 0.35304978 0.15154111 0.01345548\n",
      " 0.21605937] Actual Label: 1\n",
      "Prediction: [0.28681386 0.10159761 0.04379469 0.22682413 0.12380656 0.04538173\n",
      " 0.17178139] Actual Label: 3\n",
      "Prediction: [0.00674538 0.05328872 0.04737564 0.5977194  0.09611104 0.00358536\n",
      " 0.1951744 ] Actual Label: 4\n",
      "Prediction: [0.00476068 0.04492323 0.01387961 0.06670079 0.00741714 0.81105924\n",
      " 0.05125932] Actual Label: 5\n",
      "Prediction: [0.02897683 0.07266735 0.16512236 0.5400884  0.09533485 0.00940705\n",
      " 0.08840318] Actual Label: 6\n",
      "Prediction: [0.01925425 0.03838668 0.14485282 0.6439318  0.06401721 0.00517547\n",
      " 0.08438178] Actual Label: 4\n",
      "Prediction: [0.01933614 0.25264078 0.45689845 0.17280021 0.04786729 0.02585579\n",
      " 0.02460138] Actual Label: 1\n",
      "Prediction: [0.01426479 0.03873193 0.16283748 0.6774041  0.0197447  0.01447825\n",
      " 0.07253875] Actual Label: 6\n",
      "Prediction: [0.01756575 0.04546546 0.07111143 0.7491228  0.02894608 0.00547567\n",
      " 0.08231273] Actual Label: 3\n",
      "Prediction: [0.02010497 0.04759955 0.00382272 0.698475   0.05305083 0.02345068\n",
      " 0.15349624] Actual Label: 6\n",
      "Prediction: [0.07373131 0.05462701 0.07670636 0.44077495 0.04621058 0.10689902\n",
      " 0.20105086] Actual Label: 5\n",
      "Prediction: [0.30359676 0.06949586 0.02243504 0.27129632 0.21233173 0.00749136\n",
      " 0.11335295] Actual Label: 0\n",
      "Prediction: [0.00899545 0.06924569 0.12940584 0.7416489  0.02737212 0.002295\n",
      " 0.02103702] Actual Label: 3\n",
      "Prediction: [0.03170467 0.08869742 0.06661546 0.31712323 0.2830429  0.00746416\n",
      " 0.2053522 ] Actual Label: 3\n",
      "Prediction: [0.04780901 0.25079402 0.07857231 0.24477759 0.11124023 0.15675583\n",
      " 0.11005098] Actual Label: 4\n",
      "Prediction: [0.06443582 0.22262493 0.03654303 0.32464224 0.08329789 0.13540065\n",
      " 0.1330555 ] Actual Label: 0\n",
      "Prediction: [0.01194092 0.2876675  0.06300727 0.52356446 0.08832869 0.00508585\n",
      " 0.02040534] Actual Label: 1\n",
      "Prediction: [0.10916776 0.0349794  0.10576355 0.56567514 0.03694574 0.02640869\n",
      " 0.12105979] Actual Label: 0\n",
      "Prediction: [0.08123494 0.12557496 0.03845939 0.49033535 0.0922467  0.0627264\n",
      " 0.10942236] Actual Label: 4\n",
      "Prediction: [0.01031637 0.03178554 0.00878175 0.6166471  0.03821151 0.02107751\n",
      " 0.2731802 ] Actual Label: 3\n",
      "Prediction: [6.4084010e-04 2.1811744e-02 1.2319522e-02 4.5521352e-02 5.9198281e-03\n",
      " 8.7671393e-01 3.7072767e-02] Actual Label: 5\n",
      "Prediction: [0.27542567 0.1671221  0.01829511 0.3116997  0.15074678 0.01769091\n",
      " 0.05901974] Actual Label: 6\n",
      "Prediction: [0.0081877  0.02020303 0.00539744 0.5886746  0.07364565 0.01235055\n",
      " 0.29154107] Actual Label: 3\n",
      "Prediction: [0.02098693 0.01914899 0.03764461 0.73290557 0.04010143 0.01064852\n",
      " 0.13856411] Actual Label: 3\n",
      "Prediction: [0.02082915 0.03710821 0.05175874 0.4974751  0.10581222 0.01466241\n",
      " 0.27235425] Actual Label: 6\n",
      "Prediction: [0.00949805 0.05501692 0.01257644 0.57357806 0.06490413 0.02590689\n",
      " 0.2585194 ] Actual Label: 3\n",
      "Prediction: [0.02793122 0.07731164 0.04410799 0.5484616  0.13881531 0.01115173\n",
      " 0.1522204 ] Actual Label: 6\n",
      "Prediction: [0.00813029 0.24638212 0.02792502 0.46280524 0.07088717 0.05264108\n",
      " 0.13122904] Actual Label: 1\n",
      "Prediction: [0.03743684 0.23704255 0.04270146 0.19978537 0.12464123 0.18896182\n",
      " 0.16943075] Actual Label: 3\n",
      "Prediction: [0.0134633  0.0431307  0.01653699 0.71024615 0.06726287 0.01858712\n",
      " 0.1307728 ] Actual Label: 3\n",
      "Prediction: [0.00794958 0.0660357  0.1129308  0.49462682 0.04190753 0.07355909\n",
      " 0.20299043] Actual Label: 2\n",
      "Prediction: [0.03007392 0.15691957 0.18769947 0.35347548 0.1676571  0.01333632\n",
      " 0.0908381 ] Actual Label: 3\n",
      "Prediction: [0.008045   0.02233369 0.0081221  0.6505975  0.04167448 0.04240705\n",
      " 0.22682017] Actual Label: 3\n",
      "Prediction: [0.0665821  0.07825205 0.19933006 0.33830634 0.16528219 0.0083867\n",
      " 0.14386067] Actual Label: 4\n",
      "Prediction: [0.00462509 0.06426184 0.02201257 0.53144825 0.02686932 0.21655731\n",
      " 0.13422564] Actual Label: 3\n",
      "Prediction: [0.11281305 0.1704646  0.04174219 0.38753775 0.19298609 0.02458037\n",
      " 0.06987591] Actual Label: 4\n",
      "Prediction: [0.00825205 0.10048518 0.37653446 0.4169004  0.047383   0.0122966\n",
      " 0.03814829] Actual Label: 6\n",
      "Prediction: [0.01775361 0.07461873 0.06279461 0.7030212  0.07864899 0.00510501\n",
      " 0.05805774] Actual Label: 3\n",
      "Prediction: [0.0008605  0.01398699 0.00496453 0.07322738 0.00444241 0.8163661\n",
      " 0.08615214] Actual Label: 5\n",
      "Prediction: [0.01045011 0.16676478 0.18727812 0.52097714 0.07293603 0.00410647\n",
      " 0.03748728] Actual Label: 3\n",
      "Prediction: [0.01262017 0.02629154 0.02239533 0.81506574 0.03350168 0.00485731\n",
      " 0.0852683 ] Actual Label: 3\n",
      "Prediction: [0.05637036 0.18037565 0.04865701 0.43018562 0.19561192 0.01178221\n",
      " 0.07701721] Actual Label: 4\n",
      "Prediction: [0.11524054 0.21466406 0.16121945 0.16945918 0.14835621 0.06502112\n",
      " 0.12603946] Actual Label: 0\n",
      "Prediction: [0.10017708 0.15219955 0.04197534 0.4543493  0.17175621 0.00858325\n",
      " 0.07095922] Actual Label: 3\n",
      "Prediction: [0.05829607 0.31122404 0.26936847 0.21119829 0.11053147 0.00816753\n",
      " 0.0312141 ] Actual Label: 4\n",
      "Prediction: [0.00629488 0.03990544 0.01445724 0.8696627  0.03438713 0.00343349\n",
      " 0.03185906] Actual Label: 4\n",
      "Prediction: [0.1924776  0.11839139 0.02513237 0.39369562 0.16488796 0.01518858\n",
      " 0.09022653] Actual Label: 3\n",
      "Prediction: [0.0677858  0.17169487 0.05079367 0.13167468 0.09063573 0.26944596\n",
      " 0.21796931] Actual Label: 5\n",
      "Prediction: [0.00253818 0.04125911 0.00744098 0.20920224 0.01936576 0.523587\n",
      " 0.19660674] Actual Label: 3\n",
      "Prediction: [0.01056888 0.14707996 0.13022514 0.28196305 0.15819137 0.0764325\n",
      " 0.19553903] Actual Label: 4\n",
      "Prediction: [0.05623449 0.07672159 0.05723807 0.59398955 0.10446396 0.02258056\n",
      " 0.08877172] Actual Label: 3\n",
      "Prediction: [0.00636285 0.01068849 0.00544266 0.7410538  0.03971954 0.00356568\n",
      " 0.1931669 ] Actual Label: 6\n",
      "Prediction: [0.01159349 0.03493861 0.02972575 0.83363634 0.02719215 0.00402434\n",
      " 0.0588894 ] Actual Label: 3\n",
      "Prediction: [0.00904885 0.13238853 0.01946968 0.1335757  0.11712904 0.47637677\n",
      " 0.11201145] Actual Label: 5\n",
      "Prediction: [0.00894487 0.13089448 0.04310166 0.63520294 0.11343129 0.00609007\n",
      " 0.06233463] Actual Label: 3\n",
      "Prediction: [0.02523207 0.01503313 0.01931263 0.25262567 0.07178952 0.02927242\n",
      " 0.5867346 ] Actual Label: 1\n",
      "Prediction: [0.06150263 0.60312057 0.04020685 0.1070047  0.10812575 0.05005555\n",
      " 0.02998404] Actual Label: 4\n",
      "Prediction: [0.0177282  0.17678787 0.3651698  0.3470008  0.02877393 0.02200844\n",
      " 0.04253102] Actual Label: 2\n",
      "Prediction: [0.00446871 0.02940192 0.11550617 0.77950007 0.01212967 0.00448324\n",
      " 0.05451031] Actual Label: 3\n",
      "Prediction: [0.03456805 0.05898774 0.01183426 0.30687866 0.22920924 0.04638748\n",
      " 0.31213465] Actual Label: 4\n",
      "Prediction: [0.00226586 0.01345436 0.01197917 0.93642133 0.01094656 0.00138232\n",
      " 0.02355052] Actual Label: 3\n",
      "Prediction: [0.01075908 0.08647779 0.05334392 0.18755573 0.07577351 0.3685294\n",
      " 0.21756049] Actual Label: 4\n",
      "Prediction: [0.19975495 0.13147303 0.09886469 0.32798204 0.13333875 0.00759797\n",
      " 0.1009886 ] Actual Label: 0\n",
      "Prediction: [0.00233853 0.02563584 0.00836805 0.68590015 0.04684598 0.04367327\n",
      " 0.18723829] Actual Label: 3\n",
      "Prediction: [0.03112384 0.22522955 0.07827792 0.3475977  0.1620732  0.0213109\n",
      " 0.13438691] Actual Label: 3\n",
      "Prediction: [0.00774234 0.27674198 0.23370805 0.29210982 0.13226797 0.00923141\n",
      " 0.04819842] Actual Label: 1\n",
      "Prediction: [0.01065487 0.04965602 0.67857456 0.15418383 0.06484228 0.00465842\n",
      " 0.03743017] Actual Label: 3\n",
      "Prediction: [0.10895441 0.02694747 0.029257   0.34495884 0.21108752 0.00415046\n",
      " 0.2746444 ] Actual Label: 0\n",
      "Prediction: [0.12178873 0.36030206 0.1312894  0.10895935 0.19743103 0.0179685\n",
      " 0.06226093] Actual Label: 0\n",
      "Prediction: [0.04128895 0.0648201  0.02292161 0.7373625  0.07850021 0.01576132\n",
      " 0.03934536] Actual Label: 3\n",
      "Prediction: [0.22977573 0.1606317  0.02234697 0.19063248 0.34874675 0.00441741\n",
      " 0.04344898] Actual Label: 0\n",
      "Prediction: [0.01753895 0.02007653 0.01122417 0.88855    0.02516915 0.00196637\n",
      " 0.03547477] Actual Label: 3\n",
      "Prediction: [0.06172994 0.03999142 0.01165274 0.7982955  0.05778081 0.00188191\n",
      " 0.0286677 ] Actual Label: 3\n",
      "Prediction: [0.12238791 0.18377404 0.01854    0.35149038 0.22280893 0.02490919\n",
      " 0.07608952] Actual Label: 4\n",
      "Prediction: [0.02753922 0.06419827 0.04525049 0.7862056  0.04555166 0.00624178\n",
      " 0.02501294] Actual Label: 3\n",
      "Prediction: [0.12702501 0.1984031  0.07135645 0.3287894  0.15518421 0.01094771\n",
      " 0.10829405] Actual Label: 3\n",
      "Prediction: [0.07157331 0.09467365 0.11758293 0.56192064 0.06679588 0.00903197\n",
      " 0.07842154] Actual Label: 3\n",
      "Prediction: [0.03723161 0.02689215 0.0102582  0.3679628  0.14036994 0.02181204\n",
      " 0.39547318] Actual Label: 6\n",
      "Prediction: [0.0068793  0.02727166 0.02153935 0.6536323  0.02916881 0.01138603\n",
      " 0.25012258] Actual Label: 3\n",
      "Prediction: [0.00459594 0.0602335  0.04017674 0.35314697 0.05846303 0.14491671\n",
      " 0.33846718] Actual Label: 6\n",
      "Prediction: [0.22732052 0.1339605  0.03458916 0.40269294 0.0910368  0.02020084\n",
      " 0.09019925] Actual Label: 5\n",
      "Prediction: [0.00227724 0.05838329 0.01510662 0.3789736  0.04655166 0.24628425\n",
      " 0.2524234 ] Actual Label: 3\n",
      "Prediction: [0.00230963 0.07161465 0.01753931 0.15617457 0.00780131 0.6440598\n",
      " 0.10050072] Actual Label: 5\n",
      "Prediction: [0.05083236 0.03400794 0.09775605 0.6730309  0.03966666 0.00733826\n",
      " 0.09736786] Actual Label: 3\n",
      "Prediction: [0.02458969 0.20647994 0.03725442 0.5291215  0.10194241 0.02375268\n",
      " 0.07685933] Actual Label: 3\n",
      "Prediction: [0.01753508 0.07660894 0.03589742 0.7798971  0.04829576 0.00931433\n",
      " 0.03245149] Actual Label: 3\n",
      "Prediction: [0.01580869 0.08777194 0.09465195 0.6554826  0.08714736 0.0022148\n",
      " 0.05692276] Actual Label: 6\n",
      "Prediction: [0.01319608 0.04093627 0.03001887 0.79099214 0.03523693 0.00863233\n",
      " 0.08098735] Actual Label: 6\n",
      "Prediction: [0.08055681 0.13858527 0.03540646 0.5326513  0.15240063 0.00337047\n",
      " 0.05702915] Actual Label: 0\n",
      "Prediction: [0.00928609 0.07893448 0.11545196 0.73505896 0.03060096 0.00472863\n",
      " 0.02593889] Actual Label: 3\n",
      "Prediction: [0.00619717 0.0942851  0.15004975 0.70539683 0.0211724  0.00468686\n",
      " 0.01821181] Actual Label: 1\n",
      "Prediction: [0.00768361 0.03722197 0.01418148 0.6276303  0.03963624 0.08214316\n",
      " 0.19150326] Actual Label: 3\n",
      "Prediction: [0.01854593 0.19387491 0.12607644 0.5206284  0.09106032 0.01616287\n",
      " 0.03365123] Actual Label: 3\n",
      "Prediction: [0.01471739 0.18176974 0.02881985 0.3468704  0.23066571 0.06596863\n",
      " 0.1311883 ] Actual Label: 4\n",
      "Prediction: [0.01963161 0.04124447 0.14625251 0.7103092  0.03348178 0.00415426\n",
      " 0.04492614] Actual Label: 2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16: \n",
    "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vgg16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     19\u001b[0m model_vgg \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     20\u001b[0m     base_model,\n\u001b[1;32m     21\u001b[0m     flatten_layer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     prediction_layer\n\u001b[1;32m     25\u001b[0m ])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m     30\u001b[0m model_vgg\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 32\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m history \u001b[38;5;241m=\u001b[39m model_vgg\u001b[38;5;241m.\u001b[39mfit(train_ds, validation_data \u001b[38;5;241m=\u001b[39m val_ds, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[es])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(7, activation='softmax')\n",
    "\n",
    "\n",
    "model_vgg = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model_vgg.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "history = model_vgg.fit(train_ds, validation_data = val_ds, epochs=10, batch_size=32, callbacks=[es])\n",
    "\n",
    "plot_history(history)\n",
    "print_predictions(model_vgg, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step\n",
      "Prediction: [0.00410895 0.05245112 0.22482607 0.5738788  0.06359594 0.0196357\n",
      " 0.06150341] Actual Label: 6\n",
      "Prediction: [0.04739311 0.13381815 0.07329758 0.20623805 0.20359476 0.24553663\n",
      " 0.09012174] Actual Label: 5\n",
      "Prediction: [0.08316551 0.13145676 0.02692242 0.14067535 0.2365763  0.27716824\n",
      " 0.10403534] Actual Label: 4\n",
      "Prediction: [0.07373614 0.07812826 0.01414828 0.10797587 0.26289803 0.40943378\n",
      " 0.05367956] Actual Label: 5\n",
      "Prediction: [0.08507486 0.06393594 0.02727791 0.39406055 0.0944519  0.11762462\n",
      " 0.21757422] Actual Label: 0\n",
      "Prediction: [0.04525127 0.16755691 0.1054664  0.2691845  0.10189566 0.04994841\n",
      " 0.2606969 ] Actual Label: 4\n",
      "Prediction: [0.00710113 0.04577387 0.08755973 0.6290746  0.13840704 0.03787905\n",
      " 0.05420462] Actual Label: 6\n",
      "Prediction: [0.00536634 0.07690225 0.43717018 0.3007303  0.01571154 0.0060522\n",
      " 0.1580673 ] Actual Label: 2\n",
      "Prediction: [0.04435897 0.10265122 0.1951215  0.31721547 0.11015192 0.07946631\n",
      " 0.15103468] Actual Label: 0\n",
      "Prediction: [0.00350952 0.02799965 0.07540275 0.7252937  0.10518958 0.0307683\n",
      " 0.03183654] Actual Label: 4\n",
      "Prediction: [0.01965948 0.16845335 0.08297101 0.27846184 0.20248662 0.16770919\n",
      " 0.08025847] Actual Label: 5\n",
      "Prediction: [0.01556147 0.24562952 0.27723336 0.1961245  0.05696874 0.02099602\n",
      " 0.18748638] Actual Label: 1\n",
      "Prediction: [0.06985212 0.09524067 0.03956132 0.36191356 0.08572815 0.07626779\n",
      " 0.27143633] Actual Label: 3\n",
      "Prediction: [0.19927227 0.07451203 0.02233147 0.1413077  0.11655201 0.25690588\n",
      " 0.18911865] Actual Label: 0\n",
      "Prediction: [0.07626407 0.18285723 0.14051461 0.16042972 0.05812154 0.05090042\n",
      " 0.33091247] Actual Label: 3\n",
      "Prediction: [0.06148697 0.12725604 0.05283403 0.3130337  0.13305631 0.08928628\n",
      " 0.22304662] Actual Label: 3\n",
      "Prediction: [0.00814337 0.05852395 0.02902161 0.6729686  0.07054107 0.02000597\n",
      " 0.1407955 ] Actual Label: 3\n",
      "Prediction: [0.03010371 0.12126905 0.07299158 0.4086235  0.10468132 0.06199294\n",
      " 0.20033793] Actual Label: 3\n",
      "Prediction: [0.15483034 0.07952898 0.02389293 0.21810396 0.0928805  0.19763398\n",
      " 0.23312925] Actual Label: 0\n",
      "Prediction: [5.1234814e-04 2.7149754e-02 9.0245172e-02 8.1456530e-01 2.4281677e-02\n",
      " 3.5812238e-03 3.9664418e-02] Actual Label: 3\n",
      "Prediction: [0.0026092  0.07277761 0.33460614 0.46148312 0.02257559 0.00691115\n",
      " 0.09903715] Actual Label: 2\n",
      "Prediction: [0.01724043 0.073668   0.01216838 0.30203304 0.3180024  0.2344418\n",
      " 0.04244599] Actual Label: 4\n",
      "Prediction: [0.00865111 0.0698491  0.18823668 0.53278834 0.0904079  0.03052433\n",
      " 0.07954238] Actual Label: 3\n",
      "Prediction: [0.02069489 0.15050755 0.3504407  0.22736599 0.0536287  0.0353884\n",
      " 0.1619739 ] Actual Label: 4\n",
      "Prediction: [0.00245962 0.06657472 0.18156242 0.61341065 0.06012461 0.01172346\n",
      " 0.06414452] Actual Label: 4\n",
      "Prediction: [0.00243958 0.05274534 0.32446992 0.51303273 0.04588161 0.0175098\n",
      " 0.04392099] Actual Label: 3\n",
      "Prediction: [0.0045547  0.11313861 0.41664508 0.307619   0.02929456 0.00789728\n",
      " 0.12085071] Actual Label: 3\n",
      "Prediction: [0.00119037 0.02708089 0.06571531 0.7871275  0.08000969 0.01449169\n",
      " 0.02438457] Actual Label: 4\n",
      "Prediction: [0.0149846  0.11342951 0.42965966 0.21114273 0.02485995 0.01135012\n",
      " 0.19457346] Actual Label: 1\n",
      "Prediction: [0.00625458 0.03798956 0.07292818 0.6450786  0.15001059 0.0533912\n",
      " 0.03434733] Actual Label: 3\n",
      "Prediction: [0.01035771 0.08362283 0.12577967 0.54143995 0.08180887 0.01957943\n",
      " 0.1374115 ] Actual Label: 3\n",
      "Prediction: [0.02861749 0.12638716 0.2206732  0.31276745 0.06557271 0.07388802\n",
      " 0.17209397] Actual Label: 3\n",
      "Prediction: [0.03699763 0.142797   0.01440182 0.12227748 0.33853856 0.28687617\n",
      " 0.05811141] Actual Label: 6\n",
      "Prediction: [0.02250515 0.17544049 0.05202515 0.23319197 0.24142948 0.20171773\n",
      " 0.07369011] Actual Label: 6\n",
      "Prediction: [0.00199214 0.01781626 0.02791137 0.77882445 0.12481927 0.03156288\n",
      " 0.01707374] Actual Label: 3\n",
      "Prediction: [0.13208613 0.05248912 0.13744813 0.27727917 0.04557808 0.08079218\n",
      " 0.27432722] Actual Label: 3\n",
      "Prediction: [0.02407464 0.05343214 0.0405184  0.37415764 0.27469257 0.18630962\n",
      " 0.0468149 ] Actual Label: 3\n",
      "Prediction: [0.14496517 0.10320345 0.03671537 0.20223525 0.11759258 0.15248966\n",
      " 0.24279854] Actual Label: 3\n",
      "Prediction: [0.03131049 0.12854575 0.01901253 0.13799435 0.30405235 0.32812735\n",
      " 0.05095717] Actual Label: 5\n",
      "Prediction: [0.00140979 0.01641937 0.0273245  0.84712815 0.06677466 0.01828833\n",
      " 0.0226553 ] Actual Label: 3\n",
      "Prediction: [0.0460236  0.05130004 0.02734051 0.34361443 0.20821957 0.25629488\n",
      " 0.0672069 ] Actual Label: 3\n",
      "Prediction: [0.11164749 0.07056012 0.02348104 0.31298044 0.09545507 0.15686879\n",
      " 0.229007  ] Actual Label: 0\n",
      "Prediction: [0.06049138 0.13304174 0.11516545 0.21399297 0.04064537 0.03239245\n",
      " 0.40427074] Actual Label: 0\n",
      "Prediction: [0.02804426 0.0414983  0.10134895 0.56287605 0.07935523 0.07646372\n",
      " 0.11041351] Actual Label: 3\n",
      "Prediction: [0.18193935 0.07830475 0.06562394 0.16249146 0.0421387  0.07581261\n",
      " 0.39368924] Actual Label: 0\n",
      "Prediction: [0.0074217  0.10024944 0.40403256 0.30667546 0.0290115  0.01102061\n",
      " 0.14158873] Actual Label: 2\n",
      "Prediction: [0.12144797 0.13493945 0.10699345 0.14440003 0.13022509 0.19654664\n",
      " 0.16544747] Actual Label: 4\n",
      "Prediction: [0.00116972 0.03103538 0.16502172 0.7012137  0.06125193 0.01971648\n",
      " 0.02059105] Actual Label: 3\n",
      "Prediction: [0.10582718 0.10928892 0.19954401 0.16263907 0.06031352 0.16646582\n",
      " 0.19592154] Actual Label: 3\n",
      "Prediction: [0.15352942 0.07513176 0.09407173 0.18855119 0.07658114 0.21665405\n",
      " 0.19548076] Actual Label: 5\n",
      "Prediction: [0.0086998  0.08683258 0.35350108 0.36777693 0.03759877 0.016652\n",
      " 0.12893882] Actual Label: 2\n",
      "Prediction: [0.13751173 0.13398325 0.06785873 0.14782007 0.05893508 0.11454223\n",
      " 0.33934894] Actual Label: 6\n",
      "Prediction: [4.4424788e-04 8.9633232e-03 1.5160927e-02 8.8309103e-01 7.0927642e-02\n",
      " 1.2723066e-02 8.6897062e-03] Actual Label: 3\n",
      "Prediction: [0.02581232 0.15889613 0.07837544 0.347416   0.15413907 0.06512656\n",
      " 0.17023456] Actual Label: 1\n",
      "Prediction: [0.02279013 0.0815172  0.2739197  0.37478575 0.07467267 0.04902644\n",
      " 0.12328801] Actual Label: 1\n",
      "Prediction: [0.10244203 0.06859532 0.03492545 0.3397685  0.09331457 0.12485958\n",
      " 0.23609453] Actual Label: 3\n",
      "Prediction: [0.01163576 0.13969687 0.18980516 0.3913207  0.07707625 0.02099633\n",
      " 0.16946894] Actual Label: 4\n",
      "Prediction: [0.06081752 0.04663799 0.0672244  0.44378066 0.07660388 0.15246285\n",
      " 0.1524727 ] Actual Label: 5\n",
      "Prediction: [0.00478601 0.07677351 0.2652265  0.48885313 0.03714288 0.01150185\n",
      " 0.1157162 ] Actual Label: 6\n",
      "Prediction: [0.00352253 0.04469521 0.1280974  0.67942595 0.06795403 0.0182271\n",
      " 0.0580777 ] Actual Label: 4\n",
      "Prediction: [0.01223067 0.18690947 0.19974236 0.33139256 0.11095473 0.04446679\n",
      " 0.11430336] Actual Label: 1\n",
      "Prediction: [0.01053998 0.08419156 0.2448405  0.3595923  0.01924412 0.00712885\n",
      " 0.27446273] Actual Label: 6\n",
      "Prediction: [0.02354887 0.10619523 0.17509516 0.39425758 0.07012124 0.02732081\n",
      " 0.20346108] Actual Label: 3\n",
      "Prediction: [0.0069637  0.03762589 0.01446249 0.73637253 0.08597064 0.03067975\n",
      " 0.08792496] Actual Label: 6\n",
      "Prediction: [0.06822995 0.16617715 0.19040915 0.16721405 0.06188409 0.05387748\n",
      " 0.2922082 ] Actual Label: 5\n",
      "Prediction: [0.08646955 0.05315908 0.03353137 0.41021502 0.08632039 0.08959875\n",
      " 0.24070588] Actual Label: 0\n",
      "Prediction: [0.00306763 0.07456615 0.19908701 0.57799244 0.05488345 0.01136695\n",
      " 0.07903633] Actual Label: 3\n",
      "Prediction: [0.07944704 0.08855074 0.14033797 0.28140268 0.06612533 0.08568966\n",
      " 0.25844654] Actual Label: 3\n",
      "Prediction: [0.08910437 0.11040456 0.03468684 0.15291363 0.19074607 0.31340078\n",
      " 0.10874379] Actual Label: 4\n",
      "Prediction: [0.27156517 0.04727608 0.02047892 0.13773783 0.05394569 0.21563984\n",
      " 0.25335652] Actual Label: 0\n",
      "Prediction: [0.0066193  0.043052   0.05729794 0.63765705 0.1655783  0.04757455\n",
      " 0.04222089] Actual Label: 1\n",
      "Prediction: [0.12533116 0.10792653 0.18977231 0.15961319 0.06428523 0.0909493\n",
      " 0.2621223 ] Actual Label: 0\n",
      "Prediction: [0.00865169 0.02452666 0.02953986 0.70921665 0.12963845 0.05434406\n",
      " 0.04408269] Actual Label: 4\n",
      "Prediction: [0.02070651 0.08912158 0.18943304 0.42132014 0.08780179 0.06887902\n",
      " 0.12273785] Actual Label: 3\n",
      "Prediction: [0.03302843 0.07833999 0.01850479 0.1611733  0.29207355 0.37722248\n",
      " 0.03965746] Actual Label: 5\n",
      "Prediction: [0.11891863 0.09322253 0.01967728 0.21699624 0.05294407 0.06743451\n",
      " 0.4308067 ] Actual Label: 6\n",
      "Prediction: [0.04091981 0.09883254 0.07737958 0.399449   0.10185377 0.06595023\n",
      " 0.21561511] Actual Label: 3\n",
      "Prediction: [0.00132874 0.03031088 0.08372614 0.789611   0.03386969 0.00652164\n",
      " 0.0546318 ] Actual Label: 3\n",
      "Prediction: [0.11955737 0.0998278  0.18793379 0.16367829 0.04131038 0.06150141\n",
      " 0.3261909 ] Actual Label: 6\n",
      "Prediction: [0.00903377 0.08271098 0.07478216 0.5549075  0.04818658 0.01160507\n",
      " 0.2187739 ] Actual Label: 3\n",
      "Prediction: [0.00500727 0.08383609 0.10776367 0.5411382  0.03038605 0.00512608\n",
      " 0.22674268] Actual Label: 6\n",
      "Prediction: [0.09916177 0.14893872 0.0648369  0.16573896 0.14969924 0.20543665\n",
      " 0.16618776] Actual Label: 1\n",
      "Prediction: [0.12309618 0.06618249 0.0535919  0.2964887  0.09193081 0.16333687\n",
      " 0.20537305] Actual Label: 3\n",
      "Prediction: [0.006089   0.02417448 0.02312233 0.75341314 0.10797161 0.04196991\n",
      " 0.04325958] Actual Label: 3\n",
      "Prediction: [0.02297857 0.10831922 0.23241387 0.30936483 0.1049281  0.13229237\n",
      " 0.089703  ] Actual Label: 2\n",
      "Prediction: [0.06814566 0.21508844 0.19078779 0.13537914 0.09339507 0.11636013\n",
      " 0.18084377] Actual Label: 3\n",
      "Prediction: [0.01937468 0.07643045 0.06958915 0.54378843 0.08334862 0.04566802\n",
      " 0.16180055] Actual Label: 3\n",
      "Prediction: [0.0378852  0.10262281 0.06627662 0.40158173 0.08072639 0.04044464\n",
      " 0.2704626 ] Actual Label: 4\n",
      "Prediction: [0.03225871 0.06875215 0.02747931 0.18730874 0.22754563 0.41495275\n",
      " 0.04170269] Actual Label: 3\n",
      "Prediction: [0.13229305 0.06437615 0.03905777 0.2933243  0.10906294 0.15222503\n",
      " 0.20966077] Actual Label: 4\n",
      "Prediction: [0.03382254 0.08069976 0.5481436  0.10779105 0.01315281 0.02094329\n",
      " 0.195447  ] Actual Label: 6\n",
      "Prediction: [1.04107356e-04 7.70235527e-03 2.26090290e-02 9.26893711e-01\n",
      " 3.20777260e-02 3.46552604e-03 7.14757619e-03] Actual Label: 3\n",
      "Prediction: [0.04470232 0.10252598 0.02329144 0.12931623 0.2511908  0.3922922\n",
      " 0.05668113] Actual Label: 5\n",
      "Prediction: [0.0131103  0.06243888 0.19371945 0.47258204 0.03732155 0.01241342\n",
      " 0.2084144 ] Actual Label: 3\n",
      "Prediction: [4.0208039e-04 1.1516539e-02 2.9071286e-02 9.0175444e-01 3.3358488e-02\n",
      " 4.5806961e-03 1.9316431e-02] Actual Label: 3\n",
      "Prediction: [0.00436168 0.02998398 0.02781657 0.7247322  0.14129049 0.03617717\n",
      " 0.03563792] Actual Label: 4\n",
      "Prediction: [0.16921496 0.09846608 0.05092902 0.1462733  0.11992002 0.22438857\n",
      " 0.19080818] Actual Label: 0\n",
      "Prediction: [0.03303582 0.06605463 0.03069427 0.44813427 0.17908306 0.15150918\n",
      " 0.09148873] Actual Label: 3\n",
      "Prediction: [0.03430846 0.17353453 0.26409414 0.2103486  0.05608464 0.04165064\n",
      " 0.21997897] Actual Label: 4\n",
      "Prediction: [0.00539893 0.03926131 0.08119886 0.69860435 0.09275711 0.02637403\n",
      " 0.05640541] Actual Label: 4\n",
      "Prediction: [0.13010843 0.1201698  0.02162858 0.18217391 0.07572751 0.12920147\n",
      " 0.34099036] Actual Label: 3\n",
      "Prediction: [0.16270262 0.05908233 0.0364239  0.13054727 0.13030602 0.36877012\n",
      " 0.11216772] Actual Label: 5\n",
      "Prediction: [0.02558948 0.10964303 0.08550968 0.41500327 0.1611231  0.07897357\n",
      " 0.12415786] Actual Label: 3\n",
      "Prediction: [0.09440807 0.15160444 0.06701737 0.1848826  0.12387209 0.15457343\n",
      " 0.22364196] Actual Label: 4\n",
      "Prediction: [2.9906968e-04 6.2806304e-03 1.2264622e-02 8.9340961e-01 7.0405930e-02\n",
      " 1.1384884e-02 5.9552290e-03] Actual Label: 3\n",
      "Prediction: [0.00984376 0.04563027 0.15964438 0.5827289  0.03357387 0.01394273\n",
      " 0.15463609] Actual Label: 6\n",
      "Prediction: [0.00468057 0.07808476 0.1163388  0.5339148  0.02727537 0.00408499\n",
      " 0.23562075] Actual Label: 3\n",
      "Prediction: [0.12058855 0.06796704 0.01851725 0.12402238 0.1902547  0.39352828\n",
      " 0.0851217 ] Actual Label: 5\n",
      "Prediction: [0.02511136 0.09785723 0.16545694 0.38623777 0.05332149 0.02225856\n",
      " 0.24975677] Actual Label: 3\n",
      "Prediction: [0.02471077 0.2000724  0.17783193 0.26621363 0.08198628 0.03697648\n",
      " 0.2122084 ] Actual Label: 1\n",
      "Prediction: [0.09549746 0.13448058 0.03910775 0.14605235 0.17688216 0.27826056\n",
      " 0.12971912] Actual Label: 4\n",
      "Prediction: [0.03333186 0.15336326 0.525985   0.07327309 0.02205365 0.02875367\n",
      " 0.16323955] Actual Label: 2\n",
      "Prediction: [5.7439774e-04 2.0501854e-02 4.4364352e-02 8.6392933e-01 2.0316770e-02\n",
      " 3.5491919e-03 4.6764225e-02] Actual Label: 3\n",
      "Prediction: [0.07865362 0.1591932  0.0186608  0.21321087 0.14577313 0.16292074\n",
      " 0.22158773] Actual Label: 4\n",
      "Prediction: [0.00176888 0.04746936 0.09044195 0.72957486 0.07383255 0.01165436\n",
      " 0.04525812] Actual Label: 3\n",
      "Prediction: [0.01872447 0.06130982 0.02931766 0.29752886 0.27359167 0.2835416\n",
      " 0.03598594] Actual Label: 4\n",
      "Prediction: [0.09785322 0.12310784 0.2127057  0.16370605 0.04496592 0.05243746\n",
      " 0.30522382] Actual Label: 0\n",
      "Prediction: [0.03522288 0.11597069 0.02912491 0.18240812 0.2657505  0.31175208\n",
      " 0.05977073] Actual Label: 3\n",
      "Prediction: [0.03357003 0.19703059 0.07290542 0.21270697 0.04472584 0.0189354\n",
      " 0.4201257 ] Actual Label: 3\n",
      "Prediction: [0.01154354 0.0776073  0.32001662 0.38781568 0.04015891 0.01856103\n",
      " 0.14429691] Actual Label: 1\n",
      "Prediction: [0.00932287 0.09285442 0.27280733 0.40287656 0.04068927 0.0120314\n",
      " 0.16941817] Actual Label: 3\n",
      "Prediction: [0.10814431 0.13384035 0.08521654 0.19231464 0.08080301 0.07765884\n",
      " 0.32202226] Actual Label: 0\n",
      "Prediction: [0.11302061 0.09296462 0.01816769 0.22354469 0.1599538  0.20729348\n",
      " 0.18505505] Actual Label: 0\n",
      "Prediction: [0.00236496 0.01472488 0.02050109 0.7732793  0.1357091  0.03728354\n",
      " 0.01613711] Actual Label: 3\n",
      "Prediction: [0.1708423  0.07943723 0.03052536 0.19796996 0.09846938 0.20697014\n",
      " 0.21578564] Actual Label: 0\n",
      "Prediction: [0.00206474 0.02073271 0.01149564 0.80724335 0.10791925 0.02478848\n",
      " 0.0257557 ] Actual Label: 3\n",
      "Prediction: [0.10266787 0.08169132 0.06555038 0.30285707 0.06726746 0.08897533\n",
      " 0.29099053] Actual Label: 3\n",
      "Prediction: [0.03704311 0.04443298 0.04081472 0.54329216 0.12012987 0.10421904\n",
      " 0.11006814] Actual Label: 4\n",
      "Prediction: [0.02017872 0.05949872 0.08628353 0.5737523  0.08817561 0.04347155\n",
      " 0.12863955] Actual Label: 3\n",
      "Prediction: [0.01336295 0.04060999 0.04214226 0.635859   0.14077291 0.06226612\n",
      " 0.06498674] Actual Label: 3\n",
      "Prediction: [0.0127502  0.04485263 0.02839212 0.6435643  0.1408809  0.0530374\n",
      " 0.07652244] Actual Label: 3\n",
      "Prediction: [0.00321041 0.04656497 0.07662159 0.7178186  0.04732796 0.00915748\n",
      " 0.09929889] Actual Label: 6\n",
      "Prediction: [0.00862355 0.10309679 0.20737708 0.4503313  0.04321711 0.0155304\n",
      " 0.17182374] Actual Label: 3\n",
      "Prediction: [0.0113307  0.11024683 0.39497322 0.25794205 0.0259994  0.01368379\n",
      " 0.18582399] Actual Label: 6\n",
      "Prediction: [0.07073037 0.07037164 0.0366101  0.37495244 0.14542525 0.15015885\n",
      " 0.1517513 ] Actual Label: 5\n",
      "Prediction: [0.0214491  0.16145407 0.22771506 0.2952391  0.08316267 0.04556564\n",
      " 0.16541436] Actual Label: 3\n",
      "Prediction: [0.0995638  0.07175682 0.12488028 0.18667886 0.11010505 0.30316183\n",
      " 0.10385346] Actual Label: 5\n",
      "Prediction: [0.0020631  0.03082874 0.10772184 0.748737   0.03258448 0.00765588\n",
      " 0.07040896] Actual Label: 3\n",
      "Prediction: [0.04626424 0.0523233  0.0638505  0.4719018  0.13084297 0.1129948\n",
      " 0.1218224 ] Actual Label: 3\n",
      "Prediction: [0.00487163 0.02658615 0.06680119 0.69549114 0.13175865 0.04530026\n",
      " 0.02919102] Actual Label: 3\n",
      "Prediction: [0.00837969 0.03231224 0.12372252 0.67322826 0.05375611 0.02763755\n",
      " 0.08096363] Actual Label: 6\n",
      "Prediction: [0.00794518 0.07157828 0.19595708 0.49354115 0.0336721  0.00938081\n",
      " 0.18792549] Actual Label: 6\n",
      "Prediction: [0.04904472 0.05062703 0.04129289 0.5044594  0.05775795 0.06021266\n",
      " 0.2366053 ] Actual Label: 0\n",
      "Prediction: [0.00171173 0.04066659 0.27150422 0.58520615 0.05210142 0.01634793\n",
      " 0.03246186] Actual Label: 3\n",
      "Prediction: [0.00810983 0.09065682 0.43308297 0.3083672  0.03856676 0.01830294\n",
      " 0.10291356] Actual Label: 1\n",
      "Prediction: [0.05718678 0.07879978 0.08187398 0.22108968 0.15164742 0.33253974\n",
      " 0.07686253] Actual Label: 3\n",
      "Prediction: [0.01436578 0.07305792 0.2184893  0.4540425  0.0864165  0.066993\n",
      " 0.08663507] Actual Label: 3\n",
      "Prediction: [0.1384578  0.06994388 0.02717062 0.18314953 0.1464536  0.302616\n",
      " 0.13220848] Actual Label: 4\n",
      "Prediction: [0.02278502 0.09585471 0.4331967  0.23009244 0.03724968 0.03074365\n",
      " 0.15007782] Actual Label: 2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50: \n",
    "https://datagen.tech/guides/computer-vision/resnet-50/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 19s/step - accuracy: 0.1033 - loss: 4.1370 - val_accuracy: 0.0867 - val_loss: 4.4002\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 19s/step - accuracy: 0.1352 - loss: 4.1698 - val_accuracy: 0.0867 - val_loss: 4.3835\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 22s/step - accuracy: 0.1479 - loss: 4.0888 - val_accuracy: 0.0867 - val_loss: 4.3678\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 21s/step - accuracy: 0.1323 - loss: 4.0540 - val_accuracy: 0.0867 - val_loss: 4.3515\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 20s/step - accuracy: 0.1338 - loss: 4.1141 - val_accuracy: 0.0867 - val_loss: 4.3346\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 21s/step - accuracy: 0.1333 - loss: 4.0541 - val_accuracy: 0.0867 - val_loss: 4.3170\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 21s/step - accuracy: 0.1299 - loss: 4.1131 - val_accuracy: 0.0867 - val_loss: 4.2990\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 22s/step - accuracy: 0.1362 - loss: 4.0270 - val_accuracy: 0.0867 - val_loss: 4.2801\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 22s/step - accuracy: 0.1362 - loss: 4.1035 - val_accuracy: 0.0867 - val_loss: 4.2620\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 20s/step - accuracy: 0.1318 - loss: 4.0819 - val_accuracy: 0.0867 - val_loss: 4.2446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30b99c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "rn50_base = tflow.keras.applications.ResNet50(\n",
    "    weights = \"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "for each_layer in rn50_base.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "resnet_model.add(rn50_base)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "resnet_model.add(Dense(7, activation='sigmoid'))\n",
    "\n",
    "resnet_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = resnet_model.fit(train_ds, validation_data = val_ds, epochs=10)\n",
    "\n",
    "plot_history(resnet_model)\n",
    "print_predictions(resnet_model, test_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step\n",
      "Prediction: [0.808961   0.3408545  0.12461656 0.16093753 0.05578974 0.320024\n",
      " 0.44170302] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.745914   0.3542185  0.1230882  0.18771501 0.05531713 0.31288648\n",
      " 0.424262  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.74697053 0.34362268 0.10176412 0.16764787 0.04852271 0.28684488\n",
      " 0.39359173] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.8429002  0.32981536 0.1052464  0.13855554 0.04150832 0.31023103\n",
      " 0.44934812] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8301681  0.3485725  0.1101438  0.14774078 0.04754231 0.32860145\n",
      " 0.44287384] Actual Label: [1 1 0 1 0 1 1]\n",
      "Prediction: [0.77808714 0.3326846  0.09886213 0.15719482 0.03974034 0.28754458\n",
      " 0.42077675] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7709208  0.33817938 0.09353303 0.15388034 0.03791275 0.29584286\n",
      " 0.40164486] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.76769364 0.32618228 0.08814462 0.1537395  0.0339381  0.2706281\n",
      " 0.4042217 ] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [0.76134753 0.34466508 0.09992874 0.15828186 0.04372464 0.3073616\n",
      " 0.3948033 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7867298  0.33598787 0.07172057 0.13143864 0.02972793 0.28088918\n",
      " 0.37583718] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.70991004 0.34237418 0.16612269 0.21958943 0.0800833  0.31050014\n",
      " 0.43659958] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7567718  0.37116188 0.13452612 0.1853667  0.06999184 0.34619296\n",
      " 0.4196186 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7845718  0.334254   0.10501549 0.15700193 0.04368808 0.29819718\n",
      " 0.41882238] Actual Label: [1 0 1 0 0 0 1]\n",
      "Prediction: [0.7508804  0.3515407  0.149137   0.2027812  0.06587361 0.32417893\n",
      " 0.45090258] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7989525  0.33387464 0.09136205 0.1425629  0.03872359 0.29240736\n",
      " 0.405594  ] Actual Label: [0 1 0 0 1 1 1]\n",
      "Prediction: [0.7660693  0.3381078  0.0916968  0.16056342 0.03770867 0.2781643\n",
      " 0.40844637] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.72944367 0.3690872  0.11014517 0.18500672 0.06054984 0.30347934\n",
      " 0.39348882] Actual Label: [1 1 0 1 0 1 0]\n",
      "Prediction: [0.75448895 0.37318328 0.12465052 0.19354306 0.06627827 0.31507915\n",
      " 0.4271151 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.77809685 0.3892187  0.08986805 0.14592756 0.05187429 0.35193554\n",
      " 0.3657211 ] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7906751  0.3118709  0.09716722 0.15062393 0.03528219 0.26924166\n",
      " 0.42485458] Actual Label: [0 0 0 1 1 0 0]\n",
      "Prediction: [0.7786637  0.37906    0.08691963 0.14427193 0.04613047 0.34010512\n",
      " 0.36991006] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7345153  0.34450004 0.13662963 0.19778223 0.05961131 0.30866402\n",
      " 0.43247995] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.6967129  0.37403402 0.11188649 0.20225702 0.06636565 0.28728876\n",
      " 0.38845798] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8201562  0.35751545 0.10299555 0.1445342  0.04894809 0.33176604\n",
      " 0.41913715] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7181222  0.36572677 0.08393533 0.15290704 0.04775679 0.3058581\n",
      " 0.33961338] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.82207257 0.3079213  0.11566345 0.15126146 0.03796022 0.29284757\n",
      " 0.46352765] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.80361444 0.3193967  0.11929966 0.16251147 0.04214735 0.29693574\n",
      " 0.4572831 ] Actual Label: [0 0 0 1 0 0 0]\n",
      "Prediction: [0.72041136 0.3807111  0.11596632 0.19321188 0.06835941 0.31426564\n",
      " 0.39213413] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.8069464  0.36196026 0.10054553 0.14394112 0.05345166 0.33006245\n",
      " 0.39725396] Actual Label: [1 1 0 0 1 1 1]\n",
      "Prediction: [0.78308666 0.36248052 0.08736941 0.14935327 0.04084731 0.31252775\n",
      " 0.3929459 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7648847  0.35788822 0.09328065 0.16403027 0.04868272 0.28337857\n",
      " 0.39608702] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.74930185 0.357151   0.09579898 0.16843481 0.04799353 0.2889853\n",
      " 0.3922824 ] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.75223035 0.32648626 0.11847539 0.1806264  0.0461567  0.28350413\n",
      " 0.43230504] Actual Label: [0 1 0 1 0 1 1]\n",
      "Prediction: [0.8247861  0.36986154 0.08485585 0.13417533 0.04106203 0.33184552\n",
      " 0.40292114] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.75355774 0.3397097  0.12408716 0.17484675 0.05665599 0.31037745\n",
      " 0.4120505 ] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7628914  0.31264162 0.14673458 0.18838695 0.05099959 0.29962754\n",
      " 0.46136433] Actual Label: [0 0 0 1 0 1 1]\n",
      "Prediction: [0.70417625 0.3475155  0.10642314 0.1817918  0.05319353 0.28588855\n",
      " 0.3787295 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8000949  0.3149742  0.13106783 0.16893086 0.04750615 0.29573005\n",
      " 0.4632491 ] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.73015445 0.37417045 0.10199573 0.17967446 0.05438243 0.3085763\n",
      " 0.38755217] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.81291914 0.3527493  0.12234982 0.16416392 0.04993314 0.3377462\n",
      " 0.45499694] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.7775339  0.32597718 0.09994759 0.14813179 0.04121937 0.29719943\n",
      " 0.39779392] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7742857  0.35344613 0.17036164 0.21144165 0.07186677 0.33926538\n",
      " 0.48590335] Actual Label: [1 0 0 0 1 0 1]\n",
      "Prediction: [0.80737674 0.37090194 0.11080588 0.15611155 0.05564931 0.34474602\n",
      " 0.42059186] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.75499177 0.3596712  0.09353269 0.15798773 0.04759327 0.30601126\n",
      " 0.37851432] Actual Label: [0 1 0 0 0 0 0]\n",
      "Prediction: [0.77229846 0.32358778 0.1293849  0.18225345 0.04921081 0.28894383\n",
      " 0.4539428 ] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.80246073 0.36314955 0.07616021 0.12737644 0.03705315 0.3219567\n",
      " 0.3825488 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.72821933 0.38395706 0.09121289 0.1524013  0.06084286 0.33356965\n",
      " 0.3370309 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7694612  0.3567228  0.10257619 0.16076712 0.04850364 0.31661424\n",
      " 0.3993751 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78060895 0.35949636 0.10660212 0.16096684 0.05201038 0.32118085\n",
      " 0.40712482] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7846029  0.34687057 0.09009457 0.1619504  0.0429094  0.26431683\n",
      " 0.41799197] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7754013  0.33911484 0.11390831 0.17586909 0.04483564 0.295053\n",
      " 0.44278562] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.8222123  0.3474558  0.11177289 0.1512244  0.04751371 0.32769254\n",
      " 0.4413684 ] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.72456557 0.34640944 0.08933891 0.16748758 0.04498303 0.2682298\n",
      " 0.3732973 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7981438  0.35114965 0.11772283 0.17604591 0.05204708 0.30007154\n",
      " 0.45571938] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7514624  0.3503501  0.1075512  0.17452759 0.05096744 0.29480174\n",
      " 0.40714955] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7934714  0.32711214 0.11292097 0.17349516 0.04427854 0.27073574\n",
      " 0.45876852] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.7536295  0.349701   0.09387544 0.1690418  0.04463288 0.27530596\n",
      " 0.40140927] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7848232  0.3517596  0.1254989  0.18576401 0.05265149 0.3078157\n",
      " 0.4606088 ] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.79496217 0.29977968 0.12628895 0.17081812 0.0390014  0.275912\n",
      " 0.47400063] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.7410051  0.32211193 0.11971534 0.18954155 0.04433972 0.27148473\n",
      " 0.44040415] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.83396155 0.35179442 0.08242977 0.13028559 0.03820061 0.30455223\n",
      " 0.41124976] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.76942825 0.36326176 0.1346444  0.18299046 0.06383757 0.34293312\n",
      " 0.43180174] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7417869  0.36138386 0.14942873 0.19841549 0.07486423 0.33971125\n",
      " 0.42736012] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7561827  0.3524564  0.12818018 0.18365975 0.06286599 0.3133481\n",
      " 0.42153633] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7285338  0.32917485 0.08836854 0.1576011  0.03897322 0.26945856\n",
      " 0.3704441 ] Actual Label: [1 0 1 1 0 0 0]\n",
      "Prediction: [0.7671294  0.34921    0.10903064 0.16925238 0.0485253  0.30660337\n",
      " 0.41579592] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7339964  0.34044152 0.13195935 0.19204512 0.05876871 0.30247948\n",
      " 0.42330012] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.80266356 0.3582279  0.08331899 0.13326259 0.04209665 0.31578344\n",
      " 0.3825225 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7976841  0.33214232 0.1108053  0.15466246 0.0440207  0.31045198\n",
      " 0.42878088] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7665948  0.3475037  0.12321419 0.1704995  0.05862654 0.32138047\n",
      " 0.41257936] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7543196  0.32337698 0.14576764 0.19412592 0.05546803 0.30036592\n",
      " 0.45524502] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7915583  0.3200763  0.09023158 0.15883395 0.03147192 0.2550455\n",
      " 0.44206885] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.73630637 0.3537787  0.12652567 0.18591896 0.06141588 0.3173279\n",
      " 0.40882626] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.82377577 0.3686495  0.09367353 0.13873763 0.04475768 0.34184918\n",
      " 0.4106728 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7855558  0.33345863 0.08887469 0.1492019  0.03764448 0.27724704\n",
      " 0.40550113] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7570433  0.33609065 0.13158666 0.19948538 0.05424891 0.28047562\n",
      " 0.45954692] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.7921034  0.33212176 0.07746296 0.1450418  0.03396542 0.2515931\n",
      " 0.40378833] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.8047826  0.35974115 0.09374306 0.14333211 0.04144218 0.3332855\n",
      " 0.40557146] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.76692945 0.3328623  0.08679721 0.15232097 0.03929178 0.26612067\n",
      " 0.39088306] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76952285 0.33247593 0.10001489 0.15579174 0.04199556 0.29311797\n",
      " 0.4021294 ] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.79663545 0.36861795 0.09841742 0.16199774 0.04842073 0.30874363\n",
      " 0.42298284] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.84667027 0.36588392 0.07925605 0.12351095 0.03358176 0.33921322\n",
      " 0.42085603] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.8441704  0.30894667 0.09900004 0.13714054 0.03460146 0.27622288\n",
      " 0.45972183] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.7816355  0.35690227 0.10020581 0.15211362 0.04639118 0.32814246\n",
      " 0.39664474] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7691905  0.3365032  0.14628142 0.18729635 0.06197252 0.3194328\n",
      " 0.44911838] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.78583467 0.37386975 0.10773865 0.16015442 0.05320673 0.343185\n",
      " 0.4201881 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7856483  0.35850045 0.09240896 0.14374135 0.04643065 0.32224447\n",
      " 0.3810994 ] Actual Label: [1 1 0 1 0 0 1]\n",
      "Prediction: [0.7548413  0.3678788  0.10673469 0.16904177 0.05496558 0.32359922\n",
      " 0.39334795] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.781453   0.31166506 0.12351014 0.17724645 0.04274204 0.27388525\n",
      " 0.46269977] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.76639616 0.36666027 0.1079822  0.16142067 0.05557041 0.33586276\n",
      " 0.39070743] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.81819797 0.2945333  0.09680216 0.14207326 0.02746497 0.26897895\n",
      " 0.45450345] Actual Label: [1 0 1 0 0 1 1]\n",
      "Prediction: [0.7689577  0.3473388  0.0882761  0.16081889 0.03728686 0.28117615\n",
      " 0.40867358] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.79697806 0.39184487 0.10606521 0.15697725 0.05977517 0.35636786\n",
      " 0.42072693] Actual Label: [1 0 1 0 1 1 1]\n",
      "Prediction: [0.74583673 0.3439476  0.09098385 0.15003888 0.041527   0.3007128\n",
      " 0.38816208] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77568394 0.35361978 0.09254922 0.15247716 0.04383274 0.30467072\n",
      " 0.3920114 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7552164  0.34167945 0.10121717 0.1643117  0.04506462 0.29300383\n",
      " 0.39924717] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7895616  0.362765   0.07437404 0.12969372 0.03432325 0.32086876\n",
      " 0.38176665] Actual Label: [1 0 1 1 1 1 0]\n",
      "Prediction: [0.70888704 0.34236664 0.11953199 0.20117493 0.05570865 0.27271128\n",
      " 0.4148804 ] Actual Label: [0 1 0 0 0 0 0]\n",
      "Prediction: [0.7943744  0.36533144 0.092902   0.14585565 0.04190764 0.33772388\n",
      " 0.39803267] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7586469  0.35690597 0.11736718 0.17051302 0.05619483 0.32748443\n",
      " 0.41132382] Actual Label: [0 1 0 1 1 1 0]\n",
      "Prediction: [0.7880801  0.3382859  0.11308236 0.15897879 0.04749437 0.31325847\n",
      " 0.42826194] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7563244  0.37780574 0.11243045 0.16892076 0.06187519 0.33947033\n",
      " 0.40838054] Actual Label: [1 0 1 0 0 1 1]\n",
      "Prediction: [0.78925484 0.36646727 0.09875689 0.15207626 0.04855812 0.32697797\n",
      " 0.41639018] Actual Label: [0 1 0 0 0 1 1]\n",
      "Prediction: [0.8006474  0.34661275 0.10768741 0.15270759 0.04690039 0.32263947\n",
      " 0.42053148] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.82804686 0.34520206 0.09303646 0.13558845 0.03821325 0.32146728\n",
      " 0.4220783 ] Actual Label: [1 0 0 1 1 1 0]\n",
      "Prediction: [0.78687453 0.33779272 0.09915795 0.16954346 0.0418472  0.26488507\n",
      " 0.4407312 ] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.8190857  0.39376944 0.08482698 0.13451852 0.04670304 0.36111063\n",
      " 0.38616   ] Actual Label: [0 1 0 1 1 1 1]\n",
      "Prediction: [0.7315268  0.354553   0.08774791 0.16723868 0.04317339 0.27781945\n",
      " 0.37836602] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77601266 0.36011457 0.09051894 0.14443925 0.04439603 0.3254604\n",
      " 0.37608522] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.727689   0.35588944 0.11708744 0.1894636  0.05595011 0.30187702\n",
      " 0.408599  ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7982076  0.3317343  0.08640828 0.13844632 0.03368556 0.29565352\n",
      " 0.40264967] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.70438    0.35223877 0.11522863 0.20344223 0.05670838 0.2731858\n",
      " 0.4101519 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.8250468  0.31774682 0.10380971 0.14452572 0.03324493 0.3030112\n",
      " 0.454642  ] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [0.7484072  0.37758616 0.13926195 0.19258714 0.08010155 0.3438577\n",
      " 0.41386563] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7974741  0.30944255 0.10413054 0.1517655  0.03538058 0.28027517\n",
      " 0.43722957] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7482879  0.33387256 0.12955035 0.19166775 0.05755872 0.28297877\n",
      " 0.4362267 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7495562  0.3611431  0.09089486 0.17410614 0.04274144 0.27987707\n",
      " 0.40518227] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.83378994 0.40072796 0.07450246 0.12049025 0.04659887 0.36084056\n",
      " 0.36664268] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7328145  0.39852902 0.0935589  0.15787935 0.06269203 0.3498625\n",
      " 0.34354436] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.74693286 0.3944244  0.10574868 0.16781346 0.06095303 0.3606849\n",
      " 0.37404093] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8045161  0.32991347 0.08087266 0.13667127 0.03440683 0.27203593\n",
      " 0.4015547 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.81353873 0.3210372  0.08158173 0.13390628 0.02869499 0.27985677\n",
      " 0.41758764] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7716489  0.35778704 0.10826235 0.17151715 0.05184067 0.30530596\n",
      " 0.4179209 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7163346  0.30595592 0.10155851 0.19669166 0.03592169 0.216152\n",
      " 0.4385109 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7846911  0.33757746 0.08598867 0.14355984 0.03676683 0.28876576\n",
      " 0.39539665] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78164095 0.36632863 0.07926686 0.14151827 0.04152379 0.30555204\n",
      " 0.371367  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.80612236 0.36760926 0.12265952 0.16306265 0.06350657 0.3439277\n",
      " 0.429218  ] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.68374765 0.36218956 0.08518679 0.17887199 0.04684994 0.26726884\n",
      " 0.3542515 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.8144134  0.35132495 0.08755343 0.13627912 0.03527728 0.32617936\n",
      " 0.40977514] Actual Label: [0 0 0 0 0 1 1]\n",
      "Prediction: [0.71496385 0.32983264 0.11225397 0.18304649 0.04781843 0.27795795\n",
      " 0.40046886] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.6841081  0.38366866 0.10989179 0.21072964 0.06750691 0.28495824\n",
      " 0.38765517] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.74513847 0.33198345 0.09947591 0.17220831 0.041612   0.26812208\n",
      " 0.40932322] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.73975766 0.38603577 0.12407044 0.1877459  0.06892131 0.348359\n",
      " 0.40118793] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.817617   0.31425142 0.12520848 0.1613536  0.04031115 0.30381683\n",
      " 0.4761149 ] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.69999385 0.3740315  0.08790511 0.17313273 0.04975189 0.294725\n",
      " 0.35311586] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.75946766 0.3405652  0.11497959 0.17660141 0.05070114 0.29295906\n",
      " 0.42263326] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76018715 0.33265218 0.11191569 0.1873293  0.04609037 0.26141384\n",
      " 0.44604185] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8232115  0.33394507 0.11016195 0.1548721  0.04011592 0.30848825\n",
      " 0.4608844 ] Actual Label: [1 1 0 0 0 0 1]\n",
      "Prediction: [0.7379286  0.37186667 0.11979238 0.19724488 0.06466521 0.30220926\n",
      " 0.41841558] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.77376264 0.345513   0.10004485 0.15828048 0.04441014 0.30239043\n",
      " 0.40477258] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.8040634  0.3262041  0.1060081  0.15155756 0.0400291  0.2997138\n",
      " 0.43404588] Actual Label: [1 0 1 1 0 1 0]\n",
      "Prediction: [0.74724585 0.3587231  0.07699172 0.152771   0.03816434 0.2815357\n",
      " 0.3669074 ] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.70353067 0.36575782 0.13344567 0.21774617 0.06836504 0.29840362\n",
      " 0.4233895 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.80026263 0.39275968 0.10925274 0.15990499 0.05834769 0.36759114\n",
      " 0.41287136] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.73107207 0.33244124 0.09416275 0.16631709 0.04329511 0.2651305\n",
      " 0.3834077 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.78651124 0.33658633 0.08823401 0.14568675 0.03721561 0.2886574\n",
      " 0.39966732] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7586522  0.36326936 0.12927249 0.19569461 0.06306595 0.310252\n",
      " 0.44048625] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.80145335 0.32790896 0.11973229 0.15949339 0.04903064 0.3046682\n",
      " 0.43945953] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.79060227 0.34696567 0.10365648 0.15744826 0.04531036 0.3085295\n",
      " 0.41927075] Actual Label: [0 0 0 0 1 1 1]\n",
      "Prediction: [0.74046737 0.37320134 0.0972959  0.17585672 0.0530656  0.2981869\n",
      " 0.389222  ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7533264  0.36076555 0.09923279 0.15906523 0.05459427 0.31057355\n",
      " 0.37377623] Actual Label: [1 0 0 1 0 0 0]\n",
      "Prediction: [0.73209447 0.36027315 0.12703843 0.19289693 0.06631429 0.3097612\n",
      " 0.41055998] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.79904604 0.35544682 0.12915598 0.1732963  0.05685587 0.3340218\n",
      " 0.4506202 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.82614046 0.347403   0.07966651 0.12554641 0.03260079 0.31925103\n",
      " 0.40129247] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.8056128  0.31942153 0.08900365 0.13688155 0.03637511 0.27659264\n",
      " 0.4062498 ] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.8158146  0.3535588  0.10174296 0.14860044 0.04385893 0.32522553\n",
      " 0.42859226] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.74576896 0.33251646 0.14848779 0.19390483 0.0623173  0.31403\n",
      " 0.43981686] Actual Label: [0 1 0 0 1 1 1]\n",
      "Prediction: [0.8174333  0.37553832 0.08603594 0.14381316 0.0403048  0.32775566\n",
      " 0.41444713] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.78429735 0.3724243  0.11763588 0.1686167  0.056137   0.35006487\n",
      " 0.42154974] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.80088085 0.3041758  0.09924512 0.15751098 0.0320181  0.2537288\n",
      " 0.45562705] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [0.7612459  0.33281702 0.09310064 0.16009794 0.04039323 0.2702458\n",
      " 0.40118784] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.77910936 0.370931   0.10839529 0.1600288  0.05556128 0.3420681\n",
      " 0.39913023] Actual Label: [0 1 0 1 0 1 1]\n",
      "Prediction: [0.7713092  0.35522753 0.12728107 0.17536107 0.05911237 0.33278766\n",
      " 0.42448547] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.81245136 0.363681   0.09609503 0.14214215 0.04622172 0.3355564\n",
      " 0.40538913] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [0.7487454  0.35652557 0.12289161 0.18035467 0.06393145 0.31396252\n",
      " 0.40625986] Actual Label: [1 1 0 0 0 0 0]\n",
      "Prediction: [0.7372966  0.37871104 0.11638834 0.18209685 0.0670052  0.3294047\n",
      " 0.39041537] Actual Label: [1 0 1 0 1 1 0]\n",
      "Prediction: [0.7526479  0.36037123 0.14290567 0.20482922 0.0681375  0.3165099\n",
      " 0.44967347] Actual Label: [1 0 1 1 0 0 0]\n",
      "Prediction: [0.79528075 0.36536312 0.10228176 0.15152285 0.04946807 0.3377135\n",
      " 0.40428388] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7722105  0.37628093 0.1288407  0.18022972 0.06375821 0.35494545\n",
      " 0.42556635] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.6752175  0.38435718 0.12487445 0.2296585  0.07466333 0.2879021\n",
      " 0.40671852] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7550782  0.34063986 0.1136255  0.16798899 0.04760118 0.31264707\n",
      " 0.41705704] Actual Label: [0 0 0 1 1 1 0]\n",
      "Prediction: [0.73588425 0.3584865  0.10376497 0.18342128 0.05148163 0.28485468\n",
      " 0.40458867] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.759135   0.37027416 0.0983601  0.16950193 0.05385826 0.3006693\n",
      " 0.39472467] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.72521603 0.33411056 0.1006797  0.18326885 0.04446381 0.25574058\n",
      " 0.40711465] Actual Label: [0 0 0 1 0 1 0]\n",
      "Prediction: [0.7129281  0.3754962  0.13774729 0.20635873 0.07480591 0.33211723\n",
      " 0.40920928] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.791514   0.31515983 0.11057665 0.17199914 0.03804827 0.26318663\n",
      " 0.46446663] Actual Label: [0 1 0 0 0 1 1]\n",
      "Prediction: [0.82603633 0.35649404 0.11717388 0.15712173 0.04877154 0.34106088\n",
      " 0.45553404] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.75639284 0.3660529  0.10200811 0.17542769 0.05251411 0.29713804\n",
      " 0.4058405 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.81112474 0.3324589  0.09774665 0.14107963 0.03913911 0.30781367\n",
      " 0.41786328] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7688447  0.3167299  0.10016754 0.16062121 0.04073181 0.2609759\n",
      " 0.4146857 ] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.75539654 0.3919474  0.10433193 0.16999395 0.06401505 0.33783427\n",
      " 0.38155553] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.737042   0.34211954 0.11375444 0.18089423 0.05415249 0.2858882\n",
      " 0.40591627] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.78171587 0.3131928  0.09439462 0.17011972 0.03335073 0.23479156\n",
      " 0.45222977] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8274153  0.34858823 0.07374824 0.12697989 0.03334038 0.2907657\n",
      " 0.40023756] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.80939823 0.3692028  0.06040328 0.1102225  0.0318998  0.3228147\n",
      " 0.33966962] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.75124556 0.36265498 0.13642156 0.1926672  0.06932481 0.32582805\n",
      " 0.4266021 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7998777  0.38448215 0.08579651 0.13845721 0.04644406 0.34624037\n",
      " 0.38707474] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.74432    0.31227845 0.11665639 0.18296026 0.04004698 0.26678205\n",
      " 0.44372445] Actual Label: [0 0 0 0 0 0 1]\n",
      "Prediction: [0.77624923 0.34261748 0.11243793 0.16931437 0.04720175 0.30424663\n",
      " 0.42843983] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7488736  0.32148165 0.10256019 0.17343606 0.03827032 0.26455823\n",
      " 0.422646  ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.69362026 0.38072702 0.13180539 0.22699426 0.07740799 0.29372752\n",
      " 0.4178262 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.75754756 0.34545517 0.09673195 0.15901384 0.04525183 0.2902595\n",
      " 0.40830275] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.77648234 0.37884435 0.07927837 0.14664495 0.04407908 0.31020764\n",
      " 0.3707463 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7860759  0.33151913 0.11782589 0.16106966 0.05328495 0.30063376\n",
      " 0.42081943] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.76762086 0.31663588 0.12832125 0.17377137 0.04857662 0.29386342\n",
      " 0.43754852] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7783509  0.32558832 0.12722173 0.17539406 0.04792943 0.30030376\n",
      " 0.448782  ] Actual Label: [1 1 0 0 1 0 1]\n",
      "Prediction: [0.75634253 0.35436237 0.1215325  0.18614267 0.06104797 0.29742303\n",
      " 0.42434916] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.8197618  0.42018327 0.07668044 0.12608503 0.05549444 0.3760292\n",
      " 0.35189998] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.802207   0.39223364 0.09755008 0.1511178  0.04963997 0.36575544\n",
      " 0.4033395 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7156221  0.3115294  0.07829472 0.17747237 0.03092672 0.20082594\n",
      " 0.403627  ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.74959534 0.33800343 0.10311786 0.16807957 0.04788928 0.2811569\n",
      " 0.39885235] Actual Label: [1 0 0 1 0 1 0]\n",
      "Prediction: [0.7064065  0.34394175 0.11310738 0.187887   0.05684739 0.28023762\n",
      " 0.38929498] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8588812  0.33319628 0.09481283 0.12843463 0.03542166 0.3151728\n",
      " 0.45253703] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7545206  0.36329317 0.11925842 0.17176555 0.0623133  0.33354342\n",
      " 0.39630538] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.8008124  0.33703658 0.10635009 0.1507686  0.04372663 0.31366014\n",
      " 0.42234966] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.76905024 0.35396025 0.11210152 0.17516987 0.0536791  0.30023122\n",
      " 0.42187166] Actual Label: [1 0 0 0 0 0 1]\n",
      "Prediction: [0.80823284 0.39367452 0.07949317 0.1325222  0.04339383 0.35842302\n",
      " 0.37240776] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.69856834 0.35237268 0.12816244 0.2087951  0.06495139 0.28569764\n",
      " 0.41054544] Actual Label: [1 0 1 0 0 0 0]\n",
      "Prediction: [0.7893722  0.32620433 0.09982088 0.16427022 0.03984937 0.26209968\n",
      " 0.4394634 ] Actual Label: [0 0 0 1 0 0 0]\n",
      "Prediction: [0.76922905 0.3354341  0.09199499 0.14491536 0.04031927 0.29359183\n",
      " 0.40846962] Actual Label: [0 0 0 1 1 1 0]\n",
      "Prediction: [0.72603923 0.38549116 0.11096831 0.1756775  0.06725655 0.33849475\n",
      " 0.38148427] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.757013   0.30468717 0.06264398 0.13378759 0.02685457 0.21155712\n",
      " 0.35989505] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.80325866 0.33021605 0.11351269 0.1549465  0.04507995 0.30839404\n",
      " 0.43836063] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.8247167  0.3428322  0.10379194 0.14550796 0.04137712 0.32201973\n",
      " 0.43875766] Actual Label: [0 1 1 0 0 0 0]\n",
      "Prediction: [0.82548946 0.3726734  0.09233142 0.13799617 0.04436508 0.34598622\n",
      " 0.41023794] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.7774383  0.39599615 0.07493199 0.13633701 0.04226269 0.33358052\n",
      " 0.41286775] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.80161846 0.37810162 0.09477381 0.14383839 0.0514206  0.34548202\n",
      " 0.3884826 ] Actual Label: [1 0 0 0 1 1 1]\n",
      "Prediction: [0.757111   0.3702272  0.08703901 0.1573894  0.04701228 0.30256948\n",
      " 0.3749255 ] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.7077564  0.37197202 0.12280526 0.20970471 0.06999288 0.2912657\n",
      " 0.4089319 ] Actual Label: [1 0 0 0 0 0 0]\n",
      "Prediction: [0.7531682  0.3382534  0.09669483 0.16827974 0.03952336 0.27933407\n",
      " 0.41008997] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8319952  0.34684822 0.09419867 0.13347885 0.04263176 0.31995213\n",
      " 0.41630965] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.80867493 0.34806302 0.09304371 0.14474323 0.03851743 0.31314322\n",
      " 0.41810563] Actual Label: [0 0 1 0 0 1 0]\n",
      "Prediction: [0.7364479  0.36862543 0.09965684 0.16899505 0.05402604 0.30546266\n",
      " 0.40101895] Actual Label: [1 0 0 0 1 1 0]\n",
      "Prediction: [0.73361397 0.35475507 0.13048834 0.19740121 0.0648018  0.3029532\n",
      " 0.4221422 ] Actual Label: [0 0 1 0 0 0 0]\n",
      "Prediction: [0.7756226  0.34447488 0.08697923 0.1428965  0.04032549 0.30033967\n",
      " 0.37804353] Actual Label: [0 1 0 1 1 0 1]\n",
      "Prediction: [0.8221242  0.33916733 0.11554173 0.15399301 0.04560582 0.3222699\n",
      " 0.45189855] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.74283534 0.36775064 0.08620666 0.15299886 0.05024789 0.3038266\n",
      " 0.3522468 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.8161666  0.32542837 0.09480921 0.13988174 0.03244103 0.30529165\n",
      " 0.4329464 ] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.80954397 0.3514116  0.10016944 0.14418498 0.04635934 0.32408777\n",
      " 0.41018662] Actual Label: [1 0 0 1 0 1 1]\n",
      "Prediction: [0.7501208  0.33682165 0.10790052 0.17883976 0.04636259 0.27550012\n",
      " 0.42098522] Actual Label: [1 0 1 0 0 1 0]\n",
      "Prediction: [0.78220665 0.36507913 0.10040243 0.157573   0.04668899 0.3294808\n",
      " 0.40512106] Actual Label: [1 1 1 0 0 1 1]\n",
      "Prediction: [0.75517505 0.32209185 0.08212215 0.15486537 0.03484203 0.24416952\n",
      " 0.39144173] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.71272457 0.3685094  0.11602322 0.1885607  0.05670093 0.32376945\n",
      " 0.40100408] Actual Label: [0 0 1 0 0 1 1]\n",
      "Prediction: [0.6880363  0.37822983 0.1428256  0.22865579 0.0837433  0.3069033\n",
      " 0.41553822] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.79399127 0.35429204 0.1127161  0.16069584 0.04836654 0.3330872\n",
      " 0.42716795] Actual Label: [0 0 1 0 1 1 0]\n",
      "Prediction: [0.76450235 0.34000283 0.10597293 0.16853708 0.04573322 0.29025713\n",
      " 0.41818282] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.7046175  0.38149118 0.12256972 0.19587635 0.07077442 0.3311573\n",
      " 0.3844754 ] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.76328766 0.34517065 0.1221268  0.17009072 0.05776001 0.31748283\n",
      " 0.41280445] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.77387625 0.34971395 0.10533305 0.17395614 0.04400326 0.29432485\n",
      " 0.43362224] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7608943  0.37109858 0.10169027 0.1606357  0.05796907 0.3229486\n",
      " 0.37873948] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7727834  0.37459016 0.09901699 0.1554218  0.04973843 0.34235567\n",
      " 0.39147392] Actual Label: [1 1 0 1 0 1 0]\n",
      "Prediction: [0.7423725  0.35252887 0.11516993 0.18585753 0.05346264 0.2969407\n",
      " 0.4175079 ] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7952781  0.3792311  0.07232088 0.13026573 0.03682657 0.32883593\n",
      " 0.37809154] Actual Label: [1 1 0 0 0 1 0]\n",
      "Prediction: [0.7407147  0.37946603 0.13307    0.20143437 0.0737917  0.3267459\n",
      " 0.42285207] Actual Label: [0 0 0 0 0 1 0]\n",
      "Prediction: [0.76738733 0.3662957  0.13117386 0.18510349 0.06467167 0.33429626\n",
      " 0.43068966] Actual Label: [1 0 0 0 0 1 1]\n",
      "Prediction: [0.8258487  0.33816597 0.08576886 0.1296252  0.03487678 0.30918092\n",
      " 0.4102045 ] Actual Label: [1 1 1 0 0 1 1]\n",
      "Prediction: [0.75537413 0.35794267 0.13642074 0.18897627 0.06518322 0.32993507\n",
      " 0.4290234 ] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.79587096 0.372929   0.09050121 0.1428274  0.04737372 0.3328954\n",
      " 0.4100687 ] Actual Label: [1 1 0 0 0 1 1]\n",
      "Prediction: [0.7793991  0.38269773 0.09030601 0.15603276 0.04598795 0.33102927\n",
      " 0.39279923] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.77008337 0.36122027 0.12437332 0.17101839 0.06586625 0.332966\n",
      " 0.40796813] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7614838  0.3460878  0.09161724 0.15396574 0.04326609 0.2929016\n",
      " 0.38379097] Actual Label: [1 0 0 1 1 1 1]\n",
      "Prediction: [0.7315846  0.36343408 0.09768003 0.17192006 0.05167006 0.29742962\n",
      " 0.37923315] Actual Label: [1 0 0 0 0 1 0]\n",
      "Prediction: [0.7638921  0.36431846 0.12721302 0.18669535 0.06293008 0.32178622\n",
      " 0.43050674] Actual Label: [0 0 0 0 1 1 0]\n",
      "Prediction: [0.70099866 0.36977416 0.10207107 0.1872501  0.05637917 0.29399097\n",
      " 0.37561074] Actual Label: [0 0 0 0 0 0 0]\n",
      "Prediction: [0.7611377  0.33721772 0.14082134 0.18903817 0.06152702 0.30858538\n",
      " 0.44295898] Actual Label: [0 0 0 0 1 0 0]\n",
      "Prediction: [0.814006   0.3344313  0.11738143 0.16624121 0.04421278 0.3000602\n",
      " 0.46828908] Actual Label: [0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print_predictions(resnet_model, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
